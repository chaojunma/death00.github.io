<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[nginx报错111: Connection refused]]></title>
    <url>%2F2019%2F06%2F06%2Fnginx%E6%8A%A5%E9%94%99111-Connection-refused%2F</url>
    <content type="text"><![CDATA[最近遇到了nginx疯狂抛错，access.log一天一共5W多条，但error.log中有大概9K多条，基本都是111: Connection refused，这到底是为什么呢？ 从日志看起我们还是先来看日志。我提取了一条error.log当中抛错的日志(稍微分一下行，否则实在太长，敏感信息稍微处理了一下):12342019/06/06 10:09:45 [error] 28652#0: *883239 connect() failed (111: Connection refused) while connecting to upstream, client: 124.104.90.145, server: xxx.xxxxx.com, request: &quot;POST /test-service/upload?mcachenum=155978698 HTTP/1.1&quot;, upstream: &quot;http://[::1]:17000/test-service/upload?mcachenum=155978698&quot;, host: &quot;xxx.xxxxx.com&quot;, referrer: &quot;https://servicewechat.com/x98b46f69/2/page-frame.html&quot; 看了一下前面的报错和后面的描述，第一眼看上去感觉都是正常。但再看之后发现，upstream中的host有些不一样。[::1]，这实际是一个IPv6的地址。 这时候你可以查看一下你的机器是否开启了IPv6的地址，linux的命令是：ip address，看看返回结果中是否出现了inet6，如果有，那么恭喜你，原因找到了。 解决办法解决方法有两种，一个是禁用你机器的IPv6配置，另一个则是修改nginx.conf中的配置。 个人觉得后一个方法更加保险一些，因为这不涉及到你的机器配置，应该相对而言最少。 nginx.conf的修改，则是针对server模块中的location，修改proxy_pass中的host，我们在网上经常看到别人用的是： proxy_pass http://localhost:18000/test-service/; 但为了强制指定IPv4的地址，需要变成： proxy_pass http://127.0.0.1:18000/test-service/; 这样操作之后，再观察nginx的error.log，应该就不会再报upstream里含有IPv6地址的错误了。 总结以上就是我这次错误的整个过程，虽然整个过程不长，但确实让我知道了，作为一个后端开发，我的知识面还是太窄了。而且Bing也是真的好用，最近无法翻墙了，暂时用Bing代替，感觉还是不错的。]]></content>
      <tags>
        <tag>nginx</tag>
        <tag>[object Object]</tag>
        <tag>upstream</tag>
        <tag>IPv6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[力扣-65不同路径]]></title>
    <url>%2F2019%2F05%2F10%2F%E5%8A%9B%E6%89%A3-65%E4%B8%8D%E5%90%8C%E8%B7%AF%E5%BE%84%2F</url>
    <content type="text"><![CDATA[最近在刷力扣上的题目，刷到了65不同路径，当初上大学的时候，曾在hihocoder上刷到过这道题目，但是现在已经几乎全忘光了，大概的知识点是动态规划，如今就让我们一起来回顾一下。 从题目说起题目原文是： 一个机器人位于一个 m x n 网格的左上角 （起始点在下图中标记为“Start” ）。 机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标记为“Finish”）。 问总共有多少条不同的路径？ 例如，上图是一个7 x 3 的网格。有多少可能的路径？ 说明：m 和 n 的值均不超过 100。 示例 1: 输入: m = 3, n = 2 输出: 3 解释: 从左上角开始，总共有 3 条路径可以到达右下角。 向右 -&gt; 向右 -&gt; 向下 向右 -&gt; 向下 -&gt; 向右 向下 -&gt; 向右 -&gt; 向右 示例 2: 输入: m = 7, n = 3 输出: 28 正向思路我们先按照正常思路来想一下，当你处于起点时，你有两个选择，向右或者向下，除非你处于最下面一排或者最右边一列，那你只有一种选择（比如处于最下面一排，你只能往右），其他位置，你都有两种选择。 因此，我们就根据这个思路，可以写出代码：123456789101112131415161718192021222324252627class Solution &#123; public int uniquePaths(int m, int n) &#123; // 特殊情况：起点即终点 if (m == 1 &amp;&amp; n == 1) &#123; return 1; &#125; // 当前处于(1,1)，终点为(m,n) return walk(1, 1, m, n); &#125; public int walk(int x, int y, int m, int n)&#123; // 已经处于终点 if (x &gt;= m &amp;&amp; y &gt;= n) &#123; return 0; &#125; // 处于最下面一排或者最右边一列 if (x &gt;= m || y &gt;= n) &#123; return 1; &#125; // 往下走，有多少种走法 int down = walk(x, y + 1, m, n); // 往右走，有多少种走法 int right = walk(x + 1, y, m, n); // 从当前(x,y)出发，走到(m,n)，共有多少种走法 return down + right; &#125;&#125; 优化我们考虑一下，这种写法，有没有可以优化的地方。 你们应该一眼就发现，walk方法的第一个判断if (x &gt;= m &amp;&amp; y &gt;= n)，永远都不可能为true，因为下一个判断if (x &gt;= m || y &gt;= n)就已经是临界点情况，直接就已经有返回值，根本不可能达到x &gt;= m &amp;&amp; y &gt;= n的情况。因此，该判断可以删除。 假设我们从(1,1)的位置出发，终点是(3,3)，那么到达(2,2)这个中间点的话有几种走法呢？两种，先到(1,2)再到(2,2)，或者，先到(2,1)再到(2,2)。 因此，如果根据我们上面的写法，从(2,2)到终点(3,3)，我们会算两次，虽然这样的思路本身是正确，但这样的情况应该是可以优化的。因为从(1,1)到(3,3)，一共只有6种路径，但已经有2条是重复的路径了，那么随着m与n越来越大，中间点会越来越多，那么重复的路径也会越来越多。 这就是前面的选择对于后面的选择会有影响，即使后面的选择相同，但由于前面的选择不同，从而也被认为是不同的选择。 很明显，后面的选择更加唯一，如果我们先在后面做出选择，那么就可以减少重复计算的次数。因此，我们可以试试反向思路。 反向思路如果我们不是从起点出发，而是从终点倒退到起点开始算的话。假设终点是(3,3)，它只能由(2,3)和(3,2)直接到达，(2,3)也只能由(2,2)和(1,3)直接到达，(1,3)只能由(1,2)直接到达，(1,2)只能由(1,1)直接到达，因此(1,3)只能由(1,1)直达。 我们可以得出规律：除了最左边一列和最上面一排的点，只能由起点(1,1)直达以外，其他的点(x,y)都是由(x-1,y)和(x,y-1)两个点直接到达的。 因此，根据这个思路，我们可以写出代码：12345678910111213141516171819class Solution &#123; public int uniquePaths(int m, int n) &#123; int[][] result = new int[m][n]; int j; for (int i = 0; i &lt; m; i++) &#123; for (j = 0; j &lt; n; j++) &#123; if (i == 0 || j == 0) &#123; // 最上面一排的点和最左边一列的点，只能由(1,1)到达 result[i][j] = 1; &#125; else &#123; // 其他的点都可以由左边的点和上面的点到达 result[i][j] = result[i - 1][j] + result[i][j - 1]; &#125; &#125; &#125; return result[m - 1][n - 1]; &#125;&#125; 其实这样的想法就已经是动态规划的范畴了，我们看看维基上的定义 动态规划（英语：Dynamic programming，简称DP）是一种在数学、管理科学、计算机科学、经济学和生物信息学中使用的，通过把原问题分解为相对简单的子问题的方式求解复杂问题的方法。 一开始我感觉很像分治法，因为都需要将一个大问题分解为子问题，但分治法最终会将子问题合并，但动态规划却不用。 优化我们考虑一下，这种写法，有没有可以优化的地方。 首先是空间上的优化，我们一定要用二维数组吗？可以用一维数组代替吗？ 答案是肯定的，因为每个点的计算只和左边与上边相邻的点有关，因此，不需要更加久远的点。 一维数组假如只用一维数组，那么只需要存储上一排的结果，如果计算到下一排的时候，则依次替换，代码为： 12345678910111213141516171819class Solution &#123; public int uniquePaths(int m, int n) &#123; int[] dp = new int[m]; int j; for(int i = 0; i &lt; n; i++) &#123; for(j = 0; j &lt; m; j++) &#123; if(j == 0) &#123; dp[j] = 1; &#125; else &#123; // 其他的点都可以由左边的点和上面的点到达 dp[j] += dp[j-1]; &#125; &#125; &#125; return dp[m-1]; &#125;&#125; 这样的优化，差不多就结束了。那我们是否可以从思路上进行优化呢？ 组合数因为我们只有向右或向下两种选择，而我们一共要走的路径其实是(m-n-2)，其中有(m-1)的路径是向右，(n-1)的路径是向下，其实可以转变为： 从(m-n-2)中挑出(m-1)，即组合数C((m-n-2), (m-1))的值 那么我们可以写出代码：12345678910111213141516class Solution &#123; public int uniquePaths(int m, int n) &#123; // 用double，因为计算出的数值会很大 double num = 1, denom = 1; // 找出更小的数，这样可以减少计算次数和计算出的数值 int small = m &gt; n ? n : m; for (int i = 1; i &lt;= small - 1; ++i) &#123; num *= m + n - 1 - i; denom *= i; &#125; return (int)(num / denom); &#125;&#125; ##总结 以上就是我做这道题的一些思路和想法了，虽然题目本身不难，但可以讨论的点还是很多的，如果大家有什么疑问，欢迎在下方留言。]]></content>
      <tags>
        <tag>Java</tag>
        <tag>力扣</tag>
        <tag>动态规划</tag>
        <tag>组合数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JWT与Session的比较]]></title>
    <url>%2F2019%2F04%2F24%2FJWT%E7%9A%84%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[如今，越来越多的项目开始采用JWT作为认证授权机制，那么它和之前的Session究竟有什么区别呢？今天就让我们来了解一下。 JWT是什么定义 JSON Web Token（JWT）是一个开放标准（RFC 7519），它定义了一种紧凑和自包含的方式，用于在各方之间作为JSON对象安全地传输信息。作为标准，它没有提供技术实现，但是大部分的语言平台都有按照它规定的内容提供了自己的技术实现，所以实际在用的时候，只要根据自己当前项目的技术平台，到官网上选用合适的实现库即可。 特点使用JWT来传输数据，实际上传输的是一个字符串，这个字符串就是所谓的json web token字符串。所以广义上，JWT是一个标准的名称；狭义上，JWT指的就是用来传递的那个token字符串。这个串有两个特点： 紧凑：指的是这个串很小，能通过url 参数，http 请求提交的数据以及http header的方式来传递； 自包含：这个串可以包含很多信息，比如用户的id、角色等，别人拿到这个串，就能拿到这些关键的业务信息，从而避免再通过数据库查询等方式才能得到它们。 结构 它由三部分组成：header（头部）、payload（载荷）、signature（签名），以.进行分割。（这个字符串本来是只有一行的，此处分成3行，只是为了区分其结构） header用来声明类型（typ）和算法（alg）。 payload一般存放一些不敏感的信息，比如用户名、权限、角色等。 signature则是将header和payload对应的json结构进行base64url编码之后得到的两个串用英文句点号拼接起来，然后根据header里面alg指定的签名算法生成出来的。 和Session的区别为什么我们要把JWT和Session做对比呢？因为我们主要在每一次请求的认证时会用JWT，在此之前我们都是用Session的。那这两者的区别在哪儿呢？ 本身的含义看了前面的介绍，我们发现JWT这个字符串其实本身就包含了关于用户的信息，比如用户名、权限、角色等。 Session传递的sessionId虽然是一个更简单的字符串，但它本身并没有任何含义。 所以一般说来JWT的字符串要比sessionId长，如果你在JWT中存储的信息越长，那么JWT本身也会越长。 而Cookie的存储容量是有限制的（通常为4KB），所以大家在使用的时候需要注意。 解析方法JWT的header和payload其实是有json转变过来的，而signature其实就是一个加密后的字符串，因此解析起来较为简单，不需要其他辅助的内容。 sessionId是服务器存储的用户对象的标识，理论上需要一个额外的map才能找出当前用户的信息。 管理方法JWT理论上用于无状态的请求，因此其用户管理也只是依赖本身而已。我们一般是在它的payload中加入过期时间，在不增加额外管理的情况下，它只有自动过期的方式。 Session因为它本就是存储在服务器端的，因此管理方案就有很多，而且大多都很成熟。 跨平台JWT本身就是基于json的，因此它是比较容易跨平台的，可以从官网下载不同平台的包，解析即可。 session的跨平台可能就不那么好做了，需要考虑的地方在于用户信息存储的格式，ProtoBuf、json、xml等，管理的话可能就需要专门的统一登录平台，这个就不展开了。 时效性无状态JWT一旦被生成，就不会再和服务端有任何瓜葛。一旦服务端中的相关数据更新，无状态JWT中存储的数据由于得不到更新，就变成了过期的数据。 session就不一样了，sessionId本身就没有太多含义，只需修改服务端中存储的数据即可。 适用场景JWTJWT的最佳用途是一次性授权Token，这种场景下的Token的特性如下： 有效期短 只希望被使用一次 真实场景的例子——文件托管服务，由两部分组成： Web 应用：这是一个可以被用户登录并维持状态的应用，用户在应用中挑选想要下载的文件。 文件下载服务：无状态下载服务，只允许通过密钥下载。 如何把JWT用在这个场景中呢？ 用户登录到 Web 应用中，挑选好想要下载的文件，点击下载。 认证服务颁发包含下载信息的、具有较短过期时间的JWT。JWT中包含的信息可以是这样的： 1234&#123; &quot;file&quot;: &quot;/books/我这一辈子.pdf&quot;, &quot;exp&quot;: 1500719759621&#125; 使用 JWT 从文件下载服务下载文件。 SessionSession比较适用于Web应用的会话管理，其特点一般是： 权限多，如果用JWT则其长度会很长，很有可能突破Cookie的存储限制。 基本信息容易变动。如果是一般的后台管理系统，肯定会涉及到人员的变化，那么其权限也会相应变化，如果使用JWT，那就需要服务器端进行主动失效，这样就将原本无状态的JWT变成有状态，改变了其本意。 总结我们使用JWT，并不是说看到它新就用，而应该考虑其适用场景，如果需要进行管理，可以考虑使用Session，毕竟其方案更加成熟。如果大家有什么新发现想和作者探讨的，欢迎在下方留言。]]></content>
      <tags>
        <tag>JWT</tag>
        <tag>Session</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP连接及其优化]]></title>
    <url>%2F2019%2F04%2F18%2FTCP%E8%BF%9E%E6%8E%A5%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[作为一个后端程序员，网络连接这块是一个绕不过的砍，当你在做服务器优化的时候，网络优化也是其中一环，那么作为网络连接中最基础的部分-TCP连接你了解吗？今天我们来仔细看看这个部分。 TCP建立连接-三次握手详解 客户端和服务器还未建立连接，但服务器一般处于listen状态 客户端主动建立连接，向服务器发送SYN报文，客户端变为SYN_SENT状态 服务器收到客户端发送的报文，也回了一个SYN报文，包含了一个ack。此时，服务器变为SYN_RCVD状态 客户端收到了服务器发送的SYN报文，确认了ack，它将向服务器发送一个ACK报文。此时，客户端变为ESTABLISHED 服务器收到客户端的ACK报文，确认了ack。此时，服务器也变为ESTABLISHED 服务器和客户端可以正常通信了 其中步骤2~4就是三次握手，那么为什么需要三次握手呢？为什么不是一次或者两次握手呢？ 首先，我们需要知道，只有当服务器和客户端都能确保自己能够发消息和接收消息，这次网络通信才算成功的。 步骤2的作用是让服务器知道了自己是可以接收消息的。 步骤3的作用是让客户端知道自己发送消息和接收消息的功能是OK的，发送消息的能力是通过服务器返回的ack=x+1确认的，因为这个值基于当初客户端发送的消息seq=x。接收消息的能力是因为收到了服务器的返回。 步骤4的作用是让服务器端知道自己发送消息的能力是OK的（和步骤3类似）。 linux查看linux服务器可以利用netstat -anp | grep tcp命令，查看服务器上各个端口和应用的连接状态。 你还可以通过修改linux的配置文件/etc/sysctl.conf，调整各个状态的数量 SYN_SENT状态相关 主动建立连接时，发SYN（步骤2）的重试次数 1nct.ipv4.tcp_syn_rctries = 6 建立连接时的本地端口可用范围 1net.ipv4.ip_local_port_range = 32768 60999 SYN_RCVD状态相关 SYN_RCVD状态连接的最大个数 1net.ipv4.tcp_max_syn_backlog 被动建立连接时，发SYN/ACK（步骤3）重试次数 1net.ipv4.tcp_synack_retries 说完了TCP建立连接，接下来，我们再来看看TCP正常断开连接的过程 TCP断开连接-四次挥手详解 客户端与服务器端正常传输数据 客户端主动断开连接，向服务器端发送FIN报文，客户端变为FIN_WAIT1状态 服务器收到客户端的FIN后，向客户端发送ACK报文，服务器变为CLOSE_WAIT状态 客户端收到服务器的ACK报文后，客户端变为FIN_WAIT2状态 服务器向客户端发送FIN报文，服务器变为LAST_ACK状态 客户端收到服务器发送的FIN报文后，向服务器发送ACK报文，客户端变为TIME_WAIT状态 服务器收到客户端的ACK报文后，服务器变为CLOSED状态 客户端经过2MSL(max segment lifetime，报文最大生存时间)时间后，也变为CLOSED状态 其中，步骤2、3、5、6即为4次挥手。 TIME_WAIT状态及其优化看完之后，大家想必会有一个疑问，为什么TIME_WAIT状态需要保持2MSL？因为这可以保证至少一次报文的往返时间内，端口是不可复用的。 假设TIME_WAIT状态的持续时间很短，我们来模拟下面这种场景： 客户端向服务器端发送了三条报文，其中第3条报文卡在网络中，服务器只收到了前两条，向客户单发送ACK=2，客户端重新发送第三条报文。 服务器主动发送FIN报文，客户端收到后发送FIN、ACK，服务器端收到后发送ACK并进入TIME_WAIT状态（假设这个状态很短）。 现在服务器又再次和客户端建立连接，三次握手之后开始发送正常数据，结果之前卡住的第三条报文，现在终于发送到服务器，但服务器也不知道该如何处理这条报文。 因此这也是TIME_WAIT状态需要保持2MSL的原因，如果这么长时间也没有收到报文，即使有正确的报文从客户端发出，也已经过期了，因此不会影响到之后的通信。 但这同样也会带来一个问题，TIME_WAIT状态保持的时间较长，假设服务器端有大量TIME_WAIT状态的TCP连接，就相当于白白浪费掉大量的服务器资源(端口)。此时，我们可以通过修改以下配置进行服务器调优：1net.ipv4.tcp_tw_reuse = 1 开启后，作为客户端时新连接可以使用仍然处于TIME_WAIT状态的端口 由于timestamp的存在，操作系统可以拒绝迟到的报文（例如上面说的第三条报文），可以利用以下配置： 1net.ipv4.tcp_timestamps = 1 其他状态的优化CLOSE_WAIT状态如果服务器端有大量CLOSE_WAIT状态的连接，很有可能是应用进程出现bug，没有及时关闭连接。 FIN_WAIT1状态调整发送FIN报文的重试次数，0相当于81net.ipv4.tcp_orphan_retries = 0 FIN_WAIT2状态调整保持在FIN_WAIT2状态的时间1net.ipv4.tcp_fin_timeout = 60 总结看到这里，想必你应该对TCP连接有了一个大致的了解。现在服务器大多都用了nginx做了负载均衡，因此，我们可能需要在此基础上了解一些nginx相关的配置原理，这样应该会对我们的服务器性能调优会有更大的帮助。有兴趣的同学不妨可以去了解一下，如果有什么新发现想和作者探讨的，欢迎在下方留言。]]></content>
      <tags>
        <tag>TCP</tag>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中容器的遍历]]></title>
    <url>%2F2019%2F04%2F17%2FJava%E4%B8%AD%E5%AE%B9%E5%99%A8%E7%9A%84%E9%81%8D%E5%8E%86%2F</url>
    <content type="text"><![CDATA[当我们用增强for循环遍历非并发容器（HashMap、ArrayList等），如果修改其结构，会抛出异常ConcurrentModificationException，因此在阿里巴巴的Java规范中有说到：不要在foreach循环里进行元素的remove/add操作，remove元素请使用Iterator方式。，但是不是真的就不可以在增强for循环中修改结构吗？其原理又是什么呢？ ConcurrentModificationException的含义ConcurrentModificationException可以将其通俗的翻译为并发修改异常，那么关注点就在并发和修改了。也许有些人会说，我只是在单线程中修改了，并没有并发操作，但系统也抛了这样的这样的错误，这是为什么呢？别急，我们看看它的源码解释： This exception may be thrown by methods that have detected concurrent modification of an object when such modification is not permissible. 这个异常就是应用程序在做一些系统不允许的操作时抛出的。记住，只要是系统不允许的操作，就一定会抛错的。 后面有一个值得注意的地方 Note that fail-fast behavior cannot be guaranteed as it is, generally speaking, impossible to make any hard guarantees in the presence of unsynchronized concurrent modification. Fail-fast operations throw ConcurrentModificationException on a best-effort basis. Therefore, it would be wrong to write a program that depended on this exception for its correctness: ConcurrentModificationException should be used only to detect bugs. fail-fast（快速失败）并不能一定被保证，所以fail-fast操作会尽最大努力抛出该异常。既然是尽最大努力，因此无论是不是并发操作，只要是修改了，就一定会报错。 既然如此，我们来看看for循环中遍历修改容器结构，系统是如何知道的。 增加for循环的原理我们来看看增强for循环遍历修改HashMap的代码：12345678910Map&lt;String, String&gt; hashMap = new HashMap&lt;&gt;(10);// 添加for (int i = 0; i &lt; 10; i++) &#123; hashMap.put(&quot;key&quot; + i, &quot;value&quot; + i);&#125;// 遍历修改for (Entry&lt;String, String&gt; entry : hashMap.entrySet()) &#123; String key = entry.getKey(); hashMap.remove(key);&#125; 这个时候，你如果运行的话，就会抛出ConcurrentModificationException，这个时候我们需要具体调试一下，发现遍历第一次并删除时没有报错，但第二次遍历，在for循环的括号执行完后，就抛出了异常，这又是为什么呢？ 让我们反编译一下class文件，看看究竟增强for循环做了什么：123456789101112Map&lt;String, String&gt; hashMap = new HashMap(10);for(int i = 0; i &lt; 10; ++i) &#123; hashMap.put(&quot;key&quot; + i, &quot;value&quot; + i);&#125;Iterator var5 = hashMap.entrySet().iterator();while(var5.hasNext()) &#123; Entry&lt;String, String&gt; entry = (Entry)var5.next(); String key = (String)entry.getKey(); hashMap.remove(key);&#125; 我们发现，虽然写法上是增强for循环，但实际还是使用的while结合iterator进行遍历，现在我们贴上这个代码进行调试。 发现在第二次var5.next()处抛异常，接下来我们看看next方法究竟做了什么？ 在HashMap的源码中显示：1234567891011121314151617final class EntryIterator extends HashIterator implements Iterator&lt;Map.Entry&lt;K,V&gt;&gt; &#123; public final Map.Entry&lt;K,V&gt; next() &#123; return nextNode(); &#125;&#125;final Node&lt;K,V&gt; nextNode() &#123; Node&lt;K,V&gt;[] t; Node&lt;K,V&gt; e = next; if (modCount != expectedModCount) throw new ConcurrentModificationException(); if (e == null) throw new NoSuchElementException(); if ((next = (current = e).next) == null &amp;&amp; (t = table) != null) &#123; do &#123;&#125; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null); &#125; return e;&#125; 我们注意到，nextNode()方法的第一个判断就决定了是否抛出ConcurrentModificationException，那么modCount和expectedModCount究竟是什么呢？ modCount和expectedModCount我们来看看modCount和expectedModCount的关系，当我们调用Iterator var5 = hashMap.entrySet().iterator();时，源代码做了什么：123456789HashIterator() &#123; expectedModCount = modCount; Node&lt;K,V&gt;[] t = table; current = next = null; index = 0; if (t != null &amp;&amp; size &gt; 0) &#123; // advance to first entry do &#123;&#125; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null); &#125;&#125; 在一开始，就让expectedModCount等于modCount，而当我们调用hashMap.remove(key);时，实际上修改了modCount的值：12345678910111213141516171819202122232425262728293031323334353637383940final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null;&#125; modCount增大1，那么，当我们下一次调用var5.next()时，自然就发现modCount和expectedModCount不等了。 修改结构的正确姿势使用增强for循环，本质还是在使用iterator，那为什么大家都在推介使用iterator.remove()呢？让我们看看源代码：1234567891011public final void remove() &#123; Node&lt;K,V&gt; p = current; if (p == null) throw new IllegalStateException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); current = null; K key = p.key; removeNode(hash(key), key, null, false, false); expectedModCount = modCount;&#125; 我们发现，这个remove方法虽然也调用了removeNode，但它在最后一步再次将modCount的值赋给expectedModCount，因此保证了下一次调用next()方法是不抛错。 所以，我们要么就直接显示地使用iterator，用它的remove方法移除对象。如果你实在想用增强for循环遍历删除，那么也只能在删除一个后，立刻退出循环。但无论用哪种方法，当多个线程同时修改时，都会有出错的可能性，因为你即时保证单个线程内的modCount和expectedModCount，但这个操作并不能保证原子性。 因此，如果在多线程环境下，我更推介使用ConcurrentHashMap，因为它没有modCount和expectedModCount的概念，因此，即时你是使用增强for循环遍历删除，也不会出现问题。]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DDL-事务的一种实现]]></title>
    <url>%2F2019%2F03%2F09%2FDDL-%E4%BA%8B%E5%8A%A1%E7%9A%84%E4%B8%80%E7%A7%8D%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[上次曾和大家说过DDL-脏数据层的实现，当时的我以为使用它的最大好处就是减少IO操作。但最近在项目中使用时，发现它也可以作为事务的一种临时实现。 大家知道，在Mongodb4.0之前是不支持事务的。因此，如果你的MongoDB使用的是低于4.0的版本，那么你一般都是在业务层去弥补，而这个DDL也可以做这样的事。 DDL中，业务场景一般是一个请求过来，直接修改缓存中的数据，我们默认这一步是成功的。后台会有一个专门的线程去定期扫描所有的脏数据，如果脏数据有脏字段，那么就将脏数据入库，入库成功自然便是皆大欢喜了，但如果不成功呢？ 记得当时用MySql数据库，项目用的Spring boot + MyBatis，利用@Transactional注解，将几个数据库操作放在一个方法，这样即便出错，也可以自动回退。 但现在我们用的是MongoDB，而且我现在的版本是3.2（坑爹的阿里云服务）。数据库本身就不支持事务，这样我的DDL在将脏数据刷入数据库时，如果抛错，那么我的缓存里依旧是正确的数据，我只需要继续记录这些没有成功刷入数据库的脏数据字段，那么缓存里的数据，就依旧是刷入数据库之前的状态。而当后续请求进来后，其访问到的，也还是缓存里的正确数据。你只需要在抛错处设置报警，这样就可以即时知道问题，此时只需要专心修改这些问题，这样脏数据就会在线程下一次运行中，将数据刷入数据库中。]]></content>
      <categories>
        <category>DDL</category>
      </categories>
      <tags>
        <tag>事务</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Disruptor原理探讨]]></title>
    <url>%2F2019%2F02%2F14%2FDisruptor%E5%8E%9F%E7%90%86%E6%8E%A2%E8%AE%A8%2F</url>
    <content type="text"><![CDATA[之前谈到了在我的项目里用到了Disruptor，因为对它了解不足的原因，才会引发之前的问题，因此，今天特意来探讨其原理。 为什么采用Disruptor先介绍一下我的这个服务。这个服务主要是作为游戏服务器的游戏逻辑部分，包括帧同步逻辑及其他在游戏过程中玩家产生的一些业务逻辑。 从用户量来说，现在最高峰大概有300人同时在线，游戏服务器设置1秒有30帧的数据量，因此，1秒内服务器接收到的请求量为30 * 300 = 9000。 虽然QPS并不是很高，但对于多人对抗竞技类游戏而言，低延迟十分重要，每一次客户端向服务器端的响应时间需要低于1/30秒（因为1秒需要发送30次）。针对这种情况，我需要的存储消息的容器应该具备快速生产、快速消费的特性。 那为什么当初要选择使用Disruptor作为存储客户端发来消息的容器，为什么不直接使用Java本身自带的那些队列结构呢？ 让我们看看Java里常用的线程安全的内置队列： 类 是否有界 是否加锁 底层数据结构 ArrayBlockingQueue 有界 加锁 数组 LinkedBlockingQueue 有界（2^31-1） 加锁 链表 ConcurrentLinkedQueue 无界 无锁 链表 LinkedTransferQueue 无界 无锁 链表 PriorityBlockingQueue 无界 加锁 堆 DelayQueue 无界 加锁 堆 一般来说我们并不会考虑堆，因为堆在实现带有优先级的队列更好。 从性能上来说，无锁时的QPS一般来说优于加锁，而ConcurrentLinkedQueue的无锁其实是通过原子变量进行compare and swap（以下简称为CAS，由CPU保证原子性）这种不加锁的方式来实现的。 但无锁的结构都是无界的，为了系统的稳定，我们需要防止生产者速度过快导致内存溢出，我们需要使队列有界；同时，为了减少Java的垃圾回收对系统性能的影响，会尽量选择array/heap（因为使用这两种结构，数据在内存中存储的地址连续）。 这样筛选下来，ArrayBlockingQueue可能相对而言更加合适，但它依旧存在性能问题——加锁、伪共享。 加锁上面也提到了，更好的方式是使用CAS，那伪共享又是什么呢？ 伪共享什么是共享下图是计算的基本结构。L1、L2、L3分别表示一级缓存、二级缓存、三级缓存，越靠近CPU的缓存，速度越快，容量也越小。所以L1缓存很小但很快，并且紧靠着在使用它的CPU内核；L2大一些，也慢一些，并且仍然只能被一个单独的CPU核使用；L3更大、更慢，并且被单个插槽上的所有CPU核共享；最后是主存，由全部插槽上的所有CPU核共享。如图： 当CPU执行运算的时候，它先去L1查找所需的数据、再去L2、然后是L3，如果最后这些缓存中都没有，所需的数据就要去主内存拿。走得越远，运算耗费的时间就越长。所以如果你在做一些很频繁的事，你要尽量确保数据在L1缓存中。 另外，线程之间共享一份数据的时候，需要一个线程把数据写回主存，而另一个线程访问主存中相应的数据。 缓存行Cache是由很多个cache line组成的。每个cache line通常是64字节，并且它有效地引用主内存中的一块儿地址。一个Java的long类型变量是8字节，因此在一个缓存行中可以存8个long类型的变量。 CPU每次从主存中拉取数据时，会把相邻的数据也存入同一个cache line。 在访问一个long数组的时候，如果数组中的一个值被加载到缓存中，它会自动加载另外7个。因此你能非常快的遍历这个数组。事实上，你可以非常快速的遍历在连续内存块中分配的任意数据结构。 下面的例子是测试利用cache line的特性和不利用cache line的特性的效果对比。 12345678910111213141516171819202122232425262728293031323334353637383940/** * 缓存行 * Cache是由很多个cache line组成的。每个cache line通常是64字节，并且它有效地引用主内存中的一块儿地址。一个Java的long类型变量是8字节，因此在一个缓存行中可以存8个long类型的变量。 * * CPU每次从主存中拉取数据时，会把相邻的数据也存入同一个cache line。 * * 在访问一个long数组的时候，如果数组中的一个值被加载到缓存中，它会自动加载另外7个。因此你能非常快的遍历这个数组。事实上，你可以非常快速的遍历在连续内存块中分配的任意数据结构。 */public class CacheLineEffect &#123; //考虑一般缓存行大小是64字节，一个 long 类型占8字节 static long[][] arr; public static void main(String[] args) &#123; arr = new long[1024 * 1024][]; for (int i = 0; i &lt; 1024 * 1024; i++) &#123; arr[i] = new long[8]; for (int j = 0; j &lt; 8; j++) &#123; arr[i][j] = 0L; &#125; &#125; long sum = 0L; long marked = System.currentTimeMillis(); for (int i = 0; i &lt; 1024 * 1024; i+=1) &#123; // 此时的8个数据其实已经直接在拿第1次的时候就全部拿下来了 for(int j =0; j&lt; 8;j++)&#123; sum = arr[i][j]; &#125; &#125; System.out.println(&quot;Loop times:&quot; + (System.currentTimeMillis() - marked) + &quot;ms&quot;); marked = System.currentTimeMillis(); for (int i = 0; i &lt; 8; i+=1) &#123; // 此时拿的数据其实同一列上的数据，从内存地址上来说并不连续 for(int j =0; j&lt; 1024 * 1024;j++)&#123; sum = arr[j][i]; &#125; &#125; System.out.println(&quot;Loop times:&quot; + (System.currentTimeMillis() - marked) + &quot;ms&quot;); &#125;&#125; 结果为：12Loop times:16msLoop times:72ms 速度差异还是比较明显的。 什么是伪共享ArrayBlockingQueue有三个成员变量： - takeIndex：需要被取走的元素下标 - putIndex：可被元素插入的位置的下标 - count：队列中元素的数量 这三个变量很容易放到一个缓存行中，但是之间修改没有太多的关联。所以每次修改，都会使之前缓存的数据失效，从而不能完全达到共享的效果。 如上图所示，当生产者线程put一个元素到ArrayBlockingQueue时，putIndex会修改，从而导致消费者线程的缓存中的缓存行无效，需要从主存中重新读取。 这种无法充分使用缓存行特性的现象，称为伪共享。 对于伪共享，一般的解决方案是，增大数组元素的间隔使得由不同线程存取的元素位于不同的缓存行上，以空间换时间。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101/** * 伪共享 * * 针对处在同一个缓存行内的数据，假设线程1修改了其中的一个数据a后，线程2想要读取数据a， * 因为a已经被修改了，因此缓存行失效，需要从主内存中重新读取。 * 这种无法充分使用缓存行特性的现象，称为伪共享。 * 当多线程修改互相独立的变量时，如果这些变量共享同一个缓存行，就会无意中影响彼此的性能，这就是伪共享。 */public class FalseSharing implements Runnable&#123; public final static long ITERATIONS = 500L * 1000L * 100L; private int arrayIndex = 0; private static ValueNoPadding[] longsNoPadding; private static ValuePadding[] longsPadding; private boolean padding; public FalseSharing(final int arrayIndex, boolean padding) &#123; this.arrayIndex = arrayIndex; this.padding = padding; &#125; public static void main(final String[] args) throws Exception &#123; for(int i=1;i&lt;10;i++)&#123; System.gc(); final long start = System.currentTimeMillis(); runTestNoPadding(i); System.out.println(&quot;NoPadding Thread num &quot;+i+&quot; duration = &quot; + (System.currentTimeMillis() - start)); &#125; for(int i=1;i&lt;10;i++)&#123; System.gc(); final long start = System.currentTimeMillis(); runTestPadding(i); System.out.println(&quot;Padding Thread num &quot;+i+&quot; duration = &quot; + (System.currentTimeMillis() - start)); &#125; &#125; private static void runTestPadding(int NUM_THREADS) throws InterruptedException &#123; Thread[] threads = new Thread[NUM_THREADS]; longsPadding = new ValuePadding[NUM_THREADS]; for (int i = 0; i &lt; longsPadding.length; i++) &#123; longsPadding[i] = new ValuePadding(); &#125; for (int i = 0; i &lt; threads.length; i++) &#123; threads[i] = new Thread(new FalseSharing(i, true)); &#125; for (Thread t : threads) &#123; t.start(); &#125; for (Thread t : threads) &#123; t.join(); &#125; &#125; private static void runTestNoPadding(int NUM_THREADS) throws InterruptedException &#123; Thread[] threads = new Thread[NUM_THREADS]; longsNoPadding = new ValueNoPadding[NUM_THREADS]; for (int i = 0; i &lt; longsNoPadding.length; i++) &#123; longsNoPadding[i] = new ValueNoPadding(); &#125; for (int i = 0; i &lt; threads.length; i++) &#123; threads[i] = new Thread(new FalseSharing(i, false)); &#125; for (Thread t : threads) &#123; t.start(); &#125; for (Thread t : threads) &#123; t.join(); &#125; &#125; public void run() &#123; long i = ITERATIONS + 1; while (0 != --i) &#123; if (padding) &#123; longsPadding[arrayIndex].value = 0L; &#125; else &#123; longsNoPadding[arrayIndex].value = 0L; &#125; &#125; &#125; public final static class ValuePadding &#123; protected long p1, p2, p3, p4, p5, p6, p7; protected volatile long value = 0L; protected long p9, p10, p11, p12, p13, p14; protected long p15; &#125; public final static class ValueNoPadding &#123; // protected long p1, p2, p3, p4, p5, p6, p7; protected volatile long value = 0L; // protected long p9, p10, p11, p12, p13, p14, p15; &#125;&#125; 结果：123456789101112131415161718NoPadding Thread num 1 duration = 394NoPadding Thread num 2 duration = 1594NoPadding Thread num 3 duration = 1702NoPadding Thread num 4 duration = 1580NoPadding Thread num 5 duration = 3217NoPadding Thread num 6 duration = 3539NoPadding Thread num 7 duration = 3269NoPadding Thread num 8 duration = 3317NoPadding Thread num 9 duration = 2800Padding Thread num 1 duration = 373Padding Thread num 2 duration = 432Padding Thread num 3 duration = 453Padding Thread num 4 duration = 490Padding Thread num 5 duration = 533Padding Thread num 6 duration = 565Padding Thread num 7 duration = 622Padding Thread num 8 duration = 685Padding Thread num 9 duration = 810 从这儿可以看出，使用了共享机制比没有使用共享机制，速度快了4倍左右。（在jdk1.8中，有专门的注解@Contended来避免伪共享，更优雅地解决问题，有兴趣地朋友可以取了解一下。） 因此，虽然ArrayBlockingQueue相对于其他队列结构而言更适合我的服务，但依旧有着性能上的缺陷，因此我选择了Disruptor。 生产者和消费者Disruptor通过环形数组结构来解决队列速度慢的问题，那具体针对生产者和消费者，它是如何保证数据读写一致性的呢？ 一个生产者写数据生产者单线程写数据的流程比较简单： 1. 申请写入m个元素； 2. 若是有m个元素可以写入，则返回最大的序列号。这儿主要判断是否会覆盖未读的元素； 3. 若是返回的正确，则生产者开始写入元素。 多个生产者多个生产者的情况下，会遇到“如何防止多个线程重复写同一个元素”的问题。Disruptor的解决方法是，每个线程获取不同的一段数组空间进行操作。这个通过CAS很容易达到。只需要在分配元素的时候，通过CAS判断一下这段空间是否已经分配出去即可。 但是会遇到一个新问题：如何防止读取的时候，读到还未写的元素。Disruptor在多个生产者的情况下，引入了一个与Ring Buffer大小相同的buffer：available Buffer。当某个位置写入成功的时候，便把availble Buffer相应的位置置位，标记为写入成功。读取的时候，会遍历available Buffer，来判断元素是否已经就绪。 下面分读数据和写数据两种情况介绍。 读数据生产者多线程写入的情况会复杂很多： 1. 申请读取到序号n； 2. 若writer cursor &gt;= n，这时仍然无法确定连续可读的最大下标。从reader cursor开始读取available Buffer，一直查到第一个不可用的元素，然后返回最大连续可读元素的位置； 3. 消费者读取元素。 如下图所示，读线程读到下标为2的元素，三个线程Writer1/Writer2/Writer3正在向RingBuffer相应位置写数据，写线程被分配到的最大元素下标是11。 读线程申请读取到下标从3到11的元素，判断writer cursor&gt;=11。然后开始读取availableBuffer，从3开始，往后读取，发现下标为7的元素没有生产成功，于是WaitFor(11)返回6。 然后，消费者读取下标从3到6共计4个元素。 写数据多个生产者写入的时候： 1. 申请写入m个元素； 2. 若是有m个元素可以写入，则返回最大的序列号。每个生产者会被分配一段独享的空间； 3. 生产者写入元素，写入元素的同时设置available Buffer里面相应的位置，以标记自己哪些位置是已经写入成功的。 如下图所示，Writer1和Writer2两个线程写入数组，都申请可写的数组空间。Writer1被分配了下标3到下表5的空间，Writer2被分配了下标6到下标9的空间。 Writer1写入下标3位置的元素，同时把available Buffer相应位置置位，标记已经写入成功，往后移一位，开始写下标4位置的元素。Writer2同样的方式。最终都写入完成。 消费者的等待策略 名称 措施 适用场景 BlockingWaitStrategy 加锁 CPU资源紧缺，吞吐量和延迟并不重要的场景 BusySpinWaitStrategy 自旋 通过不断重试，减少切换线程导致的系统调用，而降低延迟。推荐在线程绑定到固定的CPU的场景下使用 PhasedBackoffWaitStrategy 自旋 + yield + 自定义策略 CPU资源紧缺，吞吐量和延迟并不重要的场景 SleepingWaitStrategy 自旋 + yield + sleep 性能和CPU资源之间有很好的折中。延迟不均匀 TimeoutBlockingWaitStrategy 加锁，有超时限制 CPU资源紧缺，吞吐量和延迟并不重要的场景 YieldingWaitStrategy 自旋 + yield + 自旋 性能和CPU资源之间有很好的折中。延迟比较均匀 从这儿可以看出，我需要的就是低延迟，因此就采用了BusySpinWaitStrategy，它虽然占用的资源多，但延迟低，非常符合我这个服务的要求。后来测试了一下其他的策略，发现都会有一些卡顿，毕竟不是一直在运行，接受到的客户端的消息就会有延迟产生。 总结Disruptor的高性能一方面是在于它没有用很重的锁，仅仅通过CPU的CAS就保证了操作的原子性；另一方面是在于它的数据结构RingBuffer（也包括Available）和Cursor的设计巧妙；当然还有它的等待策略、线程池等等。 如果你有什么意见或者建议，欢迎在下方评论。]]></content>
      <tags>
        <tag>Java</tag>
        <tag>Disruptor</tag>
        <tag>缓存行</tag>
        <tag>RingBuffer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线上Java服务使用Disruptor导致CPU占用超过100%的问题排查]]></title>
    <url>%2F2019%2F02%2F13%2F%E6%B8%B8%E6%88%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B9%8BDisruptor%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[最近看了一下部署游戏后台的服务器状况，发现我的一个Java程序其占用的CPU时长超过100%，排查后发现竟是Disruptor引起的，让我们来看看究竟为什么Disruptor会有这样的表现。 发现占用CPU时间超过100%的进程首先是在服务器上用top命令查看服务器状态，发现有一个应用程序占用的CPU时长超过100%，如图： 我根据进程号查了一下，发现是我的一个Java游戏后台服务，有一个CPU几乎被占满，因此继续排查究竟是什么代码导致了这种情况。 用top -Hp 27538将这个进程的所有线程显示出来，按照CPU占用时间排序，看到了这个结果： 27658线程占用了近乎所有的CPU时间，而且一直都是，因此查看这个进程的详细信息。 用jstack pid &gt; pid.log命令将该进程的进程快照输出到一个文件中，下载下来。 将27658转换为16进制0x6c0a后在线程快照中查询(因为线程快照中线程ID都是16进制存放，所以需要转换)：1234567&quot;disruptor-0&quot; #27 prio=5 os_prio=0 tid=0x00007fa100c58000 nid=0x6c0a runnable [0x00007fa0ae080000] java.lang.Thread.State: RUNNABLE at com.lmax.disruptor.BusySpinWaitStrategy.waitFor(BusySpinWaitStrategy.java:39) at com.lmax.disruptor.ProcessingSequenceBarrier.waitFor(ProcessingSequenceBarrier.java:56) at com.lmax.disruptor.BatchEventProcessor.processEvents(BatchEventProcessor.java:159) at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:125) at java.lang.Thread.run(Thread.java:748) 这是Disruptor的一个堆栈，为了更直观地查看线程的状态信息，可以将快照上传到专门的分析平台上。 （博主本人对于进程快照分析也是处于新手阶段，如果大家有什么建议或者意见，欢迎在下方留言。） 分析Disruptor为何会占用整个CPU根据上面快照的分析，实际是Disruptor的等待策略相关的线程所导致的，查看BusySpinWaitStrategy类，发现有相关说明：12* This strategy will use CPU resource to avoid syscalls which can introduce latency jitter. It is best* used when threads can be bound to specific CPU cores. 现在终于知道了，原来是因为这个策略就是让线程绑定了一个CPU核心，自然其CPU占用时间就超过100%了。 总结通过这一次问题的排查，不仅了解了linux系统中进程、线程的关系，也开始着手java服务的线上排查，顺便也回顾了一下之前有过接触的Disruptor。如果大家有什么建议或者意见，欢迎在下方留言]]></content>
      <tags>
        <tag>Java</tag>
        <tag>Disruptor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java服务器获取客户端的真实IP]]></title>
    <url>%2F2018%2F11%2F12%2FJava%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%8E%B7%E5%8F%96%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84%E7%9C%9F%E5%AE%9EIP%2F</url>
    <content type="text"><![CDATA[在进行一些小游戏开发时，我们经常比较关注的一个功能便是分享。针对分享，我们希望能根据各个城市或者地区，能有不同的分享文案，辨识地区的功能如果由服务器来完成的话，我们就需要知道客户端的真实IP。今天我们就来看看服务器是如何获取到客户端的真实IP的。 nginx配置首先，一个请求肯定是可以分为请求头和请求体的，而我们客户端的IP地址信息一般都是存储在请求头里的。如果你的服务器有用Nginx做负载均衡的话，你需要在你的location里面配置X-Real-IP和X-Forwarded-For请求头： 12345location ^~ /your-service/ &#123; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://localhost:60000/your-service/;&#125; X-Real-IP在《实战nginx》中，有这么一句话：1经过反向代理后，由于在客户端和web服务器之间增加了中间层，因此web服务器无法直接拿到客户端的ip，通过$remote_addr变量拿到的将是反向代理服务器的ip地址。 这句话的意思是说，当你使用了nginx反向服务器后，在web端使用request.getRemoteAddr()（本质上就是获取$remote_addr），取得的是nginx的地址，即$remote_addr变量中封装的是nginx的地址，当然是没法获得用户的真实ip的。但是，nginx是可以获得用户的真实ip的，也就是说nginx使用$remote_addr变量时获得的是用户的真实ip，如果我们想要在web端获得用户的真实ip，就必须在nginx里作一个赋值操作，即我在上面的配置：1proxy_set_header X-Real-IP $remote_addr; X-Forwarded-ForX-Forwarded-For变量，这是一个squid开发的，用于识别通过HTTP代理或负载平衡器原始IP一个连接到Web服务器的客户机地址的非rfc标准，如果有做X-Forwarded-For设置的话,每次经过proxy转发都会有记录,格式就是client1,proxy1,proxy2以逗号隔开各个地址，由于它是非rfc标准，所以默认是没有的，需要强制添加。在默认情况下经过proxy转发的请求，在后端看来远程地址都是proxy端的ip 。也就是说在默认情况下我们使用request.getAttribute(&quot;X-Forwarded-For&quot;)获取不到用户的ip，如果我们想要通过这个变量获得用户的ip，我们需要自己在nginx添加配置：1proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 意思是增加一个$proxy_add_x_forwarded_for到X-Forwarded-For里去，注意是增加，而不是覆盖，当然由于默认的X-Forwarded-For值是空的，所以我们总感觉X-Forwarded-For的值就等于$proxy_add_x_forwarded_for的值，实际上当你搭建两台nginx在不同的ip上，并且都使用了这段配置，那你会发现在web服务器端通过request.getAttribute(&quot;X-Forwarded-For&quot;)获得的将会是客户端ip和第一台nginx的ip。 那么$proxy_add_x_forwarded_for又是什么？ $proxy_add_x_forwarded_for变量包含客户端请求头中的X-Forwarded-For与$remote_addr两部分，他们之间用逗号分开。 举个例子，有一个web应用，在它之前通过了两个nginx转发，www.linuxidc.com即用户访问该web通过两台nginx。 在第一台nginx中,使用： 1proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 现在的$proxy_add_x_forwarded_for变量的X-Forwarded-For部分是空的，所以只有$remote_addr，而$remote_addr的值是用户的ip，于是赋值以后，X-Forwarded-For变量的值就是用户的真实的ip地址了。 到了第二台nginx，使用：1proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 现在的$proxy_add_x_forwarded_for变量，X-Forwarded-For部分包含的是用户的真实ip，$remote_addr部分的值是上一台nginx的ip地址，于是通过这个赋值以后现在的X-Forwarded-For的值就变成了“用户的真实ip，第一台nginx的ip”，这样就清楚了吧。 服务器获取真实IP代码为： 12345678910111213141516171819202122232425262728293031323334public static String getIpAddress(HttpServletRequest request) &#123; String Xip = request.getHeader("X-Real-IP"); String XFor = request.getHeader("X-Forwarded-For"); if (!Strings.isNullOrEmpty(XFor) &amp;&amp; !"unKnown".equalsIgnoreCase(XFor)) &#123; //多次反向代理后会有多个ip值，第一个ip才是真实ip int index = XFor.indexOf(","); if (index != -1) &#123; return XFor.substring(0, index); &#125; else &#123; return XFor; &#125; &#125; XFor = Xip; if (!Strings.isNullOrEmpty(XFor) &amp;&amp; !"unKnown".equalsIgnoreCase(XFor)) &#123; return XFor; &#125; if (Strings.nullToEmpty(XFor).trim().isEmpty() || "unknown".equalsIgnoreCase(XFor)) &#123; XFor = request.getHeader("Proxy-Client-IP"); &#125; if (Strings.nullToEmpty(XFor).trim().isEmpty() || "unknown".equalsIgnoreCase(XFor)) &#123; XFor = request.getHeader("WL-Proxy-Client-IP"); &#125; if (Strings.nullToEmpty(XFor).trim().isEmpty() || "unknown".equalsIgnoreCase(XFor)) &#123; XFor = request.getHeader("HTTP_CLIENT_IP"); &#125; if (Strings.nullToEmpty(XFor).trim().isEmpty() || "unknown".equalsIgnoreCase(XFor)) &#123; XFor = request.getHeader("HTTP_X_FORWARDED_FOR"); &#125; if (Strings.nullToEmpty(XFor).trim().isEmpty() || "unknown".equalsIgnoreCase(XFor)) &#123; XFor = request.getRemoteAddr(); &#125; return XFor;&#125; 我们来看看各个请求头的含义 X-Real-IPnginx代理一般会加上此请求头。 X-FORWARDED-FOR这是一个Squid开发的字段，只有在通过了HTTP代理或者负载均衡服务器时才会添加该项。 Proxy-Client-IP 和 WL-Proxy-Client-IP这个一般是经过apache http服务器的请求才会有，用apache http做代理时一般会加上Proxy-Client-IP请求头，而WL-Proxy-Client-IP是它的weblogic插件加上的头。 HTTP_CLIENT_IP有些代理服务器会加上此请求头。在网上搜了一下，有一个说法是：123456789101112这是普通的 http header，伪造起来很容易，不要轻易信任用户输入。 curl -H &apos;client-ip: 8.8.8.8&apos; lidian.club/phpinfo.php | grep _SERVER 你就能看到 _SERVER[&quot;HTTP_CLIENT_IP&quot;] 了。 client-ip 和 client-host 是在 NAPT 还没普及的年代，企业内网假设的 http 透明代理，传给服务器的 header，只有极少数厂家用过，从来不是标准，也从来没成为过事实标准。 （大家最熟悉的事实标准就是 x-forwarded-for） 后来出现的 web proxy 也没见用过这个 header。 TCP/IP Illustrated Vol 3 没有讲过这个 header，网上的传言不可信。 可考的最早痕迹出现在2005年，日本一部 Perl/CGI 秘籍（9784798010779，270页）通过 client-ip 与 via 两个 header 屏蔽代理用户访问。 HTTP_X_FORWARDED_FOR简称XFF头，它代表客户端，也就是HTTP的请求端真实的IP，只有在通过了HTTP 代理(比如APACHE代理)或者负载均衡服务器时才会添加该项。它不是RFC中定义的标准请求头信息，在squid缓存代理服务器开发文档中可以找到该项的详细介绍。如果有该条信息, 说明您使用了代理服务器，地址就是后面的数值。可以伪造。标准格式如下：X-Forwarded-For: client1, proxy1, proxy2 总结以上就是我在处理客户端真实IP的方法，如果你有什么意见或者建议，可以在下方留言。]]></content>
      <tags>
        <tag>Java</tag>
        <tag>nginx</tag>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中List的sort源码解读]]></title>
    <url>%2F2018%2F11%2F02%2Fjava%E4%B8%ADList%E7%9A%84sort%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[最近看了一些排序相关的文章，因此比较好奇，Java中的排序是如何做的。本片文章介绍的是JDK1.8，List中的sort方法。 先来看看List中的sort是怎么写的：12345678910@SuppressWarnings(&#123;"unchecked", "rawtypes"&#125;)default void sort(Comparator&lt;? super E&gt; c) &#123; Object[] a = this.toArray(); Arrays.sort(a, (Comparator) c); ListIterator&lt;E&gt; i = this.listIterator(); for (Object e : a) &#123; i.next(); i.set((E) e); &#125;&#125; 首先，你需要传入一个比较器作为参数，这个好理解，毕竟你肯定要定一个比较标准。然后就是将list转换成一个数组，再对这个数组进行排序，排序完之后，再利用iterator重新改变list。 接着，我们再来看看Arrays.sort：123456789101112131415161718192021222324public static &lt;T&gt; void sort(T[] a, Comparator&lt;? super T&gt; c) &#123; if (c == null) &#123; sort(a); &#125; else &#123; if (LegacyMergeSort.userRequested) legacyMergeSort(a, c); else TimSort.sort(a, 0, a.length, c, null, 0, 0); &#125;&#125;public static void sort(Object[] a) &#123; if (LegacyMergeSort.userRequested) legacyMergeSort(a); else ComparableTimSort.sort(a, 0, a.length, null, 0, 0);&#125;static final class LegacyMergeSort &#123; private static final boolean userRequested = java.security.AccessController.doPrivileged( new sun.security.action.GetBooleanAction( "java.util.Arrays.useLegacyMergeSort")).booleanValue();&#125; 这样可以看出，其实排序的核心就是TimSort，LegacyMergeSort大致意思是表明如果版本很旧的话，就用这个，新版本是不会采用这种排序方式的。 我们再来看看TimSort的实现：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849private static final int MIN_MERGE = 32;static &lt;T&gt; void sort(T[] a, int lo, int hi, Comparator&lt;? super T&gt; c, T[] work, int workBase, int workLen) &#123; assert c != null &amp;&amp; a != null &amp;&amp; lo &gt;= 0 &amp;&amp; lo &lt;= hi &amp;&amp; hi &lt;= a.length; int nRemaining = hi - lo; if (nRemaining &lt; 2) return; // Arrays of size 0 and 1 are always sorted // If array is small, do a "mini-TimSort" with no merges if (nRemaining &lt; MIN_MERGE) &#123; // 获得最长的递增序列 int initRunLen = countRunAndMakeAscending(a, lo, hi, c); binarySort(a, lo, hi, lo + initRunLen, c); return; &#125; /** * March over the array once, left to right, finding natural runs, * extending short natural runs to minRun elements, and merging runs * to maintain stack invariant. */ TimSort&lt;T&gt; ts = new TimSort&lt;&gt;(a, c, work, workBase, workLen); int minRun = minRunLength(nRemaining); do &#123; // Identify next run int runLen = countRunAndMakeAscending(a, lo, hi, c); // If run is short, extend to min(minRun, nRemaining) if (runLen &lt; minRun) &#123; int force = nRemaining &lt;= minRun ? nRemaining : minRun; binarySort(a, lo, lo + force, lo + runLen, c); runLen = force; &#125; // Push run onto pending-run stack, and maybe merge ts.pushRun(lo, runLen); ts.mergeCollapse(); // Advance to find next run lo += runLen; nRemaining -= runLen; &#125; while (nRemaining != 0); // Merge all remaining runs to complete sort assert lo == hi; ts.mergeForceCollapse(); assert ts.stackSize == 1;&#125; 如果小于2个，代表不再不需要排序；如果小于32个，则采用优化的二分排序。怎么优化的呢？首先获得最长的递增序列： 123456789101112131415161718192021private static &lt;T&gt; int countRunAndMakeAscending(T[] a, int lo, int hi, Comparator&lt;? super T&gt; c) &#123; assert lo &lt; hi; int runHi = lo + 1; if (runHi == hi) return 1; // Find end of run, and reverse range if descending if (c.compare(a[runHi++], a[lo]) &lt; 0) &#123; // Descending // 一开始是递减序列，就找出最长递减序列的最后一个下标 while (runHi &lt; hi &amp;&amp; c.compare(a[runHi], a[runHi - 1]) &lt; 0) runHi++; // 逆转前面的递减序列 reverseRange(a, lo, runHi); &#125; else &#123; // Ascending while (runHi &lt; hi &amp;&amp; c.compare(a[runHi], a[runHi - 1]) &gt;= 0) runHi++; &#125; return runHi - lo;&#125; 接着进行二分排序：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748private static &lt;T&gt; void binarySort(T[] a, int lo, int hi, int start, Comparator&lt;? super T&gt; c) &#123; assert lo &lt;= start &amp;&amp; start &lt;= hi; if (start == lo) start++; for ( ; start &lt; hi; start++) &#123; T pivot = a[start]; // Set left (and right) to the index where a[start] (pivot) belongs int left = lo; int right = start; assert left &lt;= right; /* * Invariants: * pivot &gt;= all in [lo, left). * pivot &lt; all in [right, start). */ // start位置是递增序列后的第一个数的位置 // 从前面的递增序列中找出start位置的数应该处于的位置 while (left &lt; right) &#123; // &gt;&gt;&gt; 无符号右移 int mid = (left + right) &gt;&gt;&gt; 1; if (c.compare(pivot, a[mid]) &lt; 0) right = mid; else left = mid + 1; &#125; assert left == right; /* * The invariants still hold: pivot &gt;= all in [lo, left) and * pivot &lt; all in [left, start), so pivot belongs at left. Note * that if there are elements equal to pivot, left points to the * first slot after them -- that's why this sort is stable. * Slide elements over to make room for pivot. */ int n = start - left; // The number of elements to move // Switch is just an optimization for arraycopy in default case // 比pivot大的数往后移动一位 switch (n) &#123; case 2: a[left + 2] = a[left + 1]; case 1: a[left + 1] = a[left]; break; default: System.arraycopy(a, left, a, left + 1, n); &#125; a[left] = pivot; &#125;&#125; 好了，待排序数量小于32个的讲完了，现在来说说大于等于32个情况。首先，获得一个叫minRun的东西，这是个啥含义呢：1234567891011int minRun = minRunLength(nRemaining);private static int minRunLength(int n) &#123; assert n &gt;= 0; int r = 0; // Becomes 1 if any 1 bits are shifted off while (n &gt;= MIN_MERGE) &#123; // 这里我没搞懂的是为什么不直接将(n &amp; 1)赋值给r，而要做一次逻辑或。 r |= (n &amp; 1); n &gt;&gt;= 1; &#125; return n + r;&#125; 各种位运算符，MIN_MERGE默认为32，如果n小于此值，那么返回n本身。否则会将n不断地右移，直到小于MIN_MERGE，同时记录一个r值，r代表最后一次移位n时，n最低位是0还是1。其实看注释比较容易理解： 1234Returns the minimum acceptable run length for an array of the specified length. Natural runs shorter than this will be extended with binarySort.Roughly speaking, the computation is: If n &lt; MIN_MERGE, return n (it&apos;s too small to bother with fancy stuff).Else if n is an exact power of 2, return MIN_MERGE/2.Else return an int k, MIN_MERGE/2 &lt;= k &lt;= MIN_MERGE, such that n/k is close to, but strictly less than, an exact power of 2. For the rationale, see listsort.txt. 返回结果其实就是用于接下来的合并排序中。 接下来就是一个while循环1234567891011121314151617181920212223do &#123; // Identify next run // 获得一个最长递增序列 int runLen = countRunAndMakeAscending(a, lo, hi, c); // If run is short, extend to min(minRun, nRemaining) // 如果最长递增序列 if (runLen &lt; minRun) &#123; int force = nRemaining &lt;= minRun ? nRemaining : minRun; binarySort(a, lo, lo + force, lo + runLen, c); runLen = force; &#125; // Push run onto pending-run stack, and maybe merge // lo——runLen为将要被归并的范围 ts.pushRun(lo, runLen); // 归并 ts.mergeCollapse(); // Advance to find next run lo += runLen; nRemaining -= runLen;&#125; while (nRemaining != 0); 这样，假设你的每次归并排序的两个序列为r1和r2，r1肯定是有序的，r2也已经被排成递增序列了，因此这样的归并排序就比较特殊了。 为什么要用归并排序呢，因为归并排序的时间复杂度永远为O(nlogn)，空间复杂度为O(n)，以空间换取时间。 好了，以上就是针对Java中的排序做的一次总结，但具体的归并代码还没有分析，其实我自己也没有完全研究透，为什么minRun的取值是这样的，这也和TimSort中的stackLen有关，有兴趣的小伙伴可以在下方留言，我们可以一起探讨。]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DDL-脏数据层的实现]]></title>
    <url>%2F2018%2F10%2F31%2FDDL-%E8%84%8F%E6%95%B0%E6%8D%AE%E5%B1%82%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[在我们的项目中，经常会有一些数据会涉及到频繁更改。如果每次都从数据库中读取再修改，这样不仅浪费时间，而且还更加危险。那此时我们究竟该如何解决这个问题呢？此时，DDL(脏数据层)就出现了。 首先说一下为什么操作不能保证原子性就会危险，因为这时就很有可能出现同时修改的情况，最终的结果极有可能并不是你所希望的（除非这些操作都是幂等性，但这种情况应该比较少）。如果是利用数据库中的锁，一来我在项目中用的比较少，二来也增加了维护难度。当然，有人说可以利用CAS，那针对一些复杂的情况（比如类里面属性的修改会有一些相关性，你的一次更改需要涉及几个属性等），可能你还是需要单独设计一套系统，而且还会有经典的ABA问题。如果你是利用CAS解决的，希望能够在下方评论区告知，就当互相学习。 那现在来说说DDL层具体是什么。DDL全称是Dirty Data Layer，即脏数据层。针对那些在系统运行经常会更改的domain类，我们将其再做一次封装，组成一个类似map的形式。单独由一组线程来管理这些map，每当有数据改动时，我们就往这个map中添加内容，而我们的线程则定期向数据库中写入内容。这样做的好处，首先是让你的每一次操作都没有IO的参与，提高了相应速度，而且定时提交意味着你可以把原本的几次提交变成为1次，减少了和数据库的交互。当然，缺点也是存在的，如果你的系统是分布式，那么你的这个DDL层的实现可能就没有那么方便，因为这些数据你可能需要存储在类似Redis这种共享缓存中，因此每次的拿和取就需要封装一下（这个应该算是小问题，因为原本就算你用的是本地缓存，所有操作依旧是需要封装的，只不过你的IO消耗由原本的数据库变成了共享缓存）。接下来，我就针对本地缓存的情况来具体实现一个DDL。 定义操作这是我定义出的一些操作：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118public interface IDirtyEntity &#123; //region manage content /** * 获取entity的内容。 */ Object getContent(); /** * 获取entity的内容。 获取的内容是复制的对象，属性值是调用该方法时的属性值。 */ Object copyContent(); //endregion //region persisting flag /** * 是否正在进行持久化 */ boolean isPersisting(); /** * 设置正在持久化标志 */ void setPersistingFlag(); /** * 清除正在持久化标志 */ void clearPersistingFlag(); //endregion //region persist state /** * 设置为脏数据状态 */ void setDirtyState(); /** * 清除脏数据状态 */ void clearDirtyState(); /** * 当前持久化状态。 * * @see PersistState */ PersistState currentPersistState(); //endregion //region get/set field /** * 获取属性值。 */ Object getField(String fieldName); /** * 设置属性值。 */ void setField(String fieldName, Object value); /** * 设置多个属性的值。 */ void setFields(List&lt;EntityField&gt; fields); /** * 增加int类型属性的值。 */ void addInt(String fieldName, int delta); /** * 增加long类型属性的值。 */ void addLong(String fieldName, long delta); //endregion //region manage dirty field /** * 标记脏数据字段 */ void addDirtyField(String fieldName); /** * 获取修改过的属性。 */ List&lt;EntityField&gt; getAndClearDirtyFields(); //endregion //region wrapper implement /** * 返回id的属性名。 */ String getIdFieldName(); /** * 返回id */ String getId(); /** * 返回DATA的class */ Class getDataClass(); //endregion&#125; 分类DDL解决的是数据频繁更改的问题，其实这里的更改说的并不准确，并不仅仅只是update，还有insert。用过mongodb的应该清楚有一种叫upsert的操作，就是找到就修改，找不到就添加。我们这里就需要将我们的数据分成两类：Detachable(可拆分的)、Nondetachable(不可拆分的)。 可拆分的，就意味着你针对这个数据的修改最小可以精确到其中的一个属性，项目中大多数都属于这种情况。 不可拆分的，即每次都是以一个整体添加，比如一次交易，每次添加都是一个整体，不可能说你先提交买方，再提交卖方，后面还会修改买方。这种类型大多都是一条记录，整体存入数据库。 因此，我们来定义一下这两种结构：可拆分的类型：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183import com.google.common.base.Preconditions;import com.google.common.base.Strings;import java.util.List;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.cglib.beans.BeanCopier;import org.springframework.cglib.beans.BeanMap;public abstract class DetachableDirtyEntityAdapter implements IDirtyEntity &#123; private static final Logger log = LoggerFactory.getLogger(DetachableDirtyEntityAdapter.class); /** * 数据属性的map引用 */ private BeanMap beanMap; private final BeanCopier beanCopier; public DetachableDirtyEntityAdapter(Object content, BeanCopier beanCopier) &#123; Preconditions.checkNotNull(content); Preconditions.checkNotNull(beanCopier); this.content = newEmptyContentInstance(); this.beanCopier = beanCopier; this.beanCopier.copy(content, this.content, null); this.beanMap = BeanMap.create(this.content); &#125; //region manage content /** * 数据的内容。 */ private Object content; @Override public Object getContent() &#123; return content; &#125; private Object newEmptyContentInstance() &#123; Class cls = getDataClass(); try &#123; return cls.newInstance(); &#125; catch (Exception e) &#123; log.error("initiate &#123;&#125; failed: &#123;&#125;", cls.getSimpleName(), e.getMessage()); return null; &#125; &#125; @Override public synchronized Object copyContent() &#123; Object copy = newEmptyContentInstance(); beanCopier.copy(this.content, copy, null); return copy; &#125; //endregion //region persisting flag private volatile boolean persisting = false; @Override public boolean isPersisting() &#123; return persisting; &#125; @Override public void setPersistingFlag() &#123; this.persisting = true; &#125; @Override public void clearPersistingFlag() &#123; this.persisting = false; &#125; //endregion //region persist state @Override public void setDirtyState() &#123; throw new UnsupportedOperationException(); &#125; @Override public void clearDirtyState() &#123; throw new UnsupportedOperationException(); &#125; @Override public synchronized PersistState currentPersistState() &#123; int dirtySize = dirtyFieldNames.size(); if (dirtySize == 0) &#123; return PersistState.PERSISTED; &#125; else &#123; return PersistState.DIRTY; &#125; &#125; //endregion //region get/set field @Override public synchronized Object getField(String fieldName) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); return beanMap.get(fieldName); &#125; @Override public synchronized void setField(String fieldName, Object value) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); beanMap.put(fieldName, value); dirtyFieldNames.add(fieldName); &#125; @Override public synchronized void setFields(List&lt;EntityField&gt; fields) &#123; Preconditions.checkNotNull(fields); for (EntityField f : fields) &#123; beanMap.put(f.getName(), f.getValue()); dirtyFieldNames.add(f.getName()); &#125; &#125; @Override public synchronized void addInt(String fieldName, int delta) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); int origin = (int) beanMap.get(fieldName); beanMap.put(fieldName, origin + delta); dirtyFieldNames.add(fieldName); &#125; @Override public synchronized void addLong(String fieldName, long delta) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); long origin = (long) beanMap.get(fieldName); beanMap.put(fieldName, origin + delta); dirtyFieldNames.add(fieldName); &#125; //endregion //region manage dirty fields /** * 当前entity的包含脏数据的属性名列表。 */ private final HashSet&lt;String&gt; dirtyFieldNames = new HashSet&lt;&gt;(16); @Override public void addDirtyField(String fieldName) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); dirtyFieldNames.add(fieldName); &#125; @Override public synchronized List&lt;EntityField&gt; getAndClearDirtyFields() &#123; ArrayList&lt;EntityField&gt; list = new ArrayList&lt;&gt;(); for (String f : dirtyFieldNames) &#123; list.add(new EntityField(f, beanMap.get(f))); &#125; // 清空dirtyFieldNames, 记录上一次持久化的事件 dirtyFieldNames.clear(); return list; &#125; //endregion&#125; 不可拆分的类型：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161import com.google.common.base.Preconditions;import com.google.common.base.Strings;import java.util.ArrayList;import java.util.HashSet;import java.util.List;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.cglib.beans.BeanCopier;import org.springframework.cglib.beans.BeanMap;public abstract class NonDetachableDirtyEntityAdapter implements IDirtyEntity &#123; private static final Logger log = LoggerFactory.getLogger(NonDetachableDirtyEntityAdapter.class); /** * 数据属性的map引用 */ private BeanMap beanMap; private final BeanCopier beanCopier; public NonDetachableDirtyEntityAdapter(Object content, BeanCopier beanCopier) &#123; Preconditions.checkNotNull(content); Preconditions.checkNotNull(beanCopier); this.content = newEmptyContentInstance(); this.beanCopier = beanCopier; this.beanCopier.copy(content, this.content, null); this.beanMap = BeanMap.create(this.content); &#125; //region manage content /** * 数据的内容。 */ private Object content; @Override public Object getContent() &#123; return content; &#125; private Object newEmptyContentInstance() &#123; Class cls = getDataClass(); try &#123; return cls.newInstance(); &#125; catch (Exception e) &#123; log.error("initiate &#123;&#125; failed: &#123;&#125;", cls.getSimpleName(), e.getMessage()); return null; &#125; &#125; @Override public synchronized Object copyContent() &#123; Object copy = newEmptyContentInstance(); beanCopier.copy(this.content, copy, null); return copy; &#125; //endregion //region persisting flag private volatile boolean persisting = false; @Override public boolean isPersisting() &#123; return persisting; &#125; @Override public void setPersistingFlag() &#123; this.persisting = true; &#125; @Override public void clearPersistingFlag() &#123; this.persisting = false; &#125; //endregion //region persist state private volatile PersistState persistState = PersistState.DIRTY; @Override public void setDirtyState() &#123; persistState = PersistState.DIRTY; &#125; @Override public void clearDirtyState() &#123; persistState = PersistState.PERSISTED; &#125; @Override public PersistState currentPersistState() &#123; return persistState; &#125; //endregion //region get/set field @Override public synchronized Object getField(String fieldName) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); return beanMap.get(fieldName); &#125; @Override public synchronized void setField(String fieldName, Object value) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); beanMap.put(fieldName, value); &#125; @Override public synchronized void setFields(List&lt;EntityField&gt; fields) &#123; Preconditions.checkNotNull(fields); for (EntityField f : fields) &#123; beanMap.put(f.getName(), f.getValue()); &#125; &#125; @Override public synchronized void addInt(String fieldName, int delta) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); int origin = (int) beanMap.get(fieldName); beanMap.put(fieldName, origin + delta); &#125; @Override public synchronized void addLong(String fieldName, long delta) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); long origin = (long) beanMap.get(fieldName); beanMap.put(fieldName, origin + delta); &#125; //endregion //region manage dirty fields @Override public void addDirtyField(String fieldName) &#123; throw new UnsupportedOperationException(); &#125; @Override public synchronized List&lt;EntityField&gt; getAndClearDirtyFields() &#123; throw new UnsupportedOperationException(); &#125; //endregion&#125; 两种类型最大的不同在于真正往数据库中存储时，前者是可以单独字段存储，后者是整体存储，因此最后和DirtyField相关的操作便需要注意，NondetachableDirtyEntityAdapter不需要记录DirtyFields。 针对原本类中属性的复制和存储，我这儿用的是spring提供的BeanCopier，如果你有什么更高效的工具，欢迎在下方留言。（我一直在找一种深度克隆高效的组件，试过kryo，但只有在实现序列化接口的前提下，其效率才能和正常的set/get大概相差10倍，如果有好的组件，希望一并告知）。 以上就是DDL的准备工作，其实后面的工作就是将具体的类做一个封装，再封装针对该类的所有操作，然后另写一个线程组执行往数据库的写入操作。这个工作其实针对各个项目都有其特殊的地方，LZ在这儿就不具体展示了，有兴趣的话大家可以在下方留言。]]></content>
      <categories>
        <category>DDL</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[log4j日志不输出的问题]]></title>
    <url>%2F2018%2F10%2F24%2Flog4j%E6%97%A5%E5%BF%97%E4%B8%8D%E8%BE%93%E5%87%BA%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[今天服务器上报错，想先去看一下日志进行排查，结果发现日志很久都没有输出过了。从上午排查到下午，刚刚解决，因此记录一下，但现在也只是知其然，并不知其所以然，所以如果大家有什么想法请在下方评论。 先说一下环境，服务器是linux，项目是运行在tomcat下的Spring项目，日志用的是log4j。 首先，从10月13号开始便没有新的日志文件了。假设日志名为log.txt（如果你设置了DailyRollingFileAppender，那么你当天的日志文件就是log.txt），先备份该文件到其他目录下，然后删除该文件，重新启动tomcat。这是为了确认你的log4j配置是否有问题，因为这是最容易出错的地方。很遗憾，我不是这里出的问题，因为项目重启后，日志文件又重新生成了，但很奇怪的是，日志文件是空的，其大小为0. 感觉自己碰上了很神奇的问题，因此我在自己的本地进行调试，启动项目后发现，正常的项目启动日志是有的：115:13:48:0253 INFO [RMI TCP Connection(3)-127.0.0.1] -Root WebApplicationContext: initialization completed in 18479 ms 但我自己的一些日志输出是不显示的，比如：12private static final Logger log = LoggerFactory.getLogger(MyDomain.class);log.info("show info log"); show info log这句话就不打印，现在证明，我的日志配置没有问题，服务器也找到了我的日志文件，但应该是我自己的Logger是不对应正确的日志输出的，因为我的console(控制台)有显示。 接下来，我就是开始看源码了。先是LoggerFactory.getLogger(Class&lt;?&gt; clazz)方法：123456789101112public static Logger getLogger(Class&lt;?&gt; clazz) &#123; Logger logger = getLogger(clazz.getName()); if (DETECT_LOGGER_NAME_MISMATCH) &#123; Class&lt;?&gt; autoComputedCallingClass = Util.getCallingClass(); if (autoComputedCallingClass != null &amp;&amp; nonMatchingClasses(clazz, autoComputedCallingClass)) &#123; Util.report(String.format("Detected logger name mismatch. Given name: \"%s\"; computed name: \"%s\".", logger.getName(), autoComputedCallingClass.getName())); Util.report("See " + LOGGER_NAME_MISMATCH_URL + " for an explanation"); &#125; &#125; return logger;&#125; 好吧，没什么用，看不出我的logger变成了，继续看getLogger(String name)方法：1234public static Logger getLogger(String name) &#123; ILoggerFactory iLoggerFactory = getILoggerFactory(); return iLoggerFactory.getLogger(name);&#125; 这时我在return iLoggerFactory.getLogger(name);这行打了断点，我看到了这样的东西： 为什么我的iLoggerFactory是用的logback中的实现？其实也是怪我自己大意，我其实依赖了一个基于Spring Boot的项目(虽然我只是用了里面的一些domain类，但因为设计不当，还没有把这些domain类单独提成一个_项目)，而Spring Boot中一般默认就依赖的logback。通过gradle查看项目的依赖树，也证实了我的这一猜想(./gradlew 子项目名称:dependencies):1234567891011| +--- org.springframework.boot:spring-boot-starter-web:2.0.2.RELEASE| | +--- org.springframework.boot:spring-boot-starter:2.0.2.RELEASE| | | +--- org.springframework.boot:spring-boot:2.0.2.RELEASE| | | | +--- org.springframework:spring-core:5.0.6.RELEASE (*)| | | | \--- org.springframework:spring-context:5.0.6.RELEASE (*)| | | +--- org.springframework.boot:spring-boot-autoconfigure:2.0.2.RELEASE| | | | \--- org.springframework.boot:spring-boot:2.0.2.RELEASE (*)| | | +--- org.springframework.boot:spring-boot-starter-logging:2.0.2.RELEASE| | | | +--- ch.qos.logback:logback-classic:1.2.3| | | | | +--- ch.qos.logback:logback-core:1.2.3| | | | | \--- org.slf4j:slf4j-api:1.7.25 接下来就好办了，你排除掉ch.qos.logback的依赖就可以了，在你的build.gradle中增加：123configurations &#123; compile.exclude group: &apos;ch.qos.logback&apos;&#125; 这个时候你再重新调试一下看看： 完美，现在是log4j中的实现，得到了我想要的操作。当然了，既然我知道之前项目中的slf4j是logback实现了，那么我自然也可以换成logback的配置，但这就需要我将项目换成用Spring Boot启动，这个改动有点大，如果以后有必要的话，我再将这个exclude删除，换成Spring Boot的形式。 这次Spring Boot帮我们默认启用的是logback，那么有没有什么简单方法可以知道呢？如果你的项目出现了以下的日志输出，说明你的项目当前有不止一个SLF4J的实现组件：12345SLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/project.war/WEB-INF/lib/logback-classic-1.2.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/project.war/WEB-INF/lib/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type [ch.qos.logback.classic.util.ContextSelectorStaticBinder] 因为在org.slf4j.LoggerFactory的bind方法中有关于这方面的输出：123456789101112131415161718192021222324252627282930313233343536373839404142434445private final static void bind() &#123; try &#123; Set&lt;URL&gt; staticLoggerBinderPathSet = null; // skip check under android, see also // http://jira.qos.ch/browse/SLF4J-328 if (!isAndroid()) &#123; // 查找你的当前项目有几个slf4j的实现 staticLoggerBinderPathSet = findPossibleStaticLoggerBinderPathSet(); // 如果多余一个就打印 reportMultipleBindingAmbiguity(staticLoggerBinderPathSet); &#125; // the next line does the binding // 这个是具体选了哪一个实现（重点关注） StaticLoggerBinder.getSingleton(); INITIALIZATION_STATE = SUCCESSFUL_INITIALIZATION; reportActualBinding(staticLoggerBinderPathSet); fixSubstituteLoggers(); replayEvents(); // release all resources in SUBST_FACTORY SUBST_FACTORY.clear(); &#125; catch (NoClassDefFoundError ncde) &#123; String msg = ncde.getMessage(); if (messageContainsOrgSlf4jImplStaticLoggerBinder(msg)) &#123; INITIALIZATION_STATE = NOP_FALLBACK_INITIALIZATION; Util.report("Failed to load class \"org.slf4j.impl.StaticLoggerBinder\"."); Util.report("Defaulting to no-operation (NOP) logger implementation"); Util.report("See " + NO_STATICLOGGERBINDER_URL + " for further details."); &#125; else &#123; failedBinding(ncde); throw ncde; &#125; &#125; catch (java.lang.NoSuchMethodError nsme) &#123; String msg = nsme.getMessage(); if (msg != null &amp;&amp; msg.contains("org.slf4j.impl.StaticLoggerBinder.getSingleton()")) &#123; INITIALIZATION_STATE = FAILED_INITIALIZATION; Util.report("slf4j-api 1.6.x (or later) is incompatible with this binding."); Util.report("Your binding is version 1.5.5 or earlier."); Util.report("Upgrade your binding to version 1.6.x."); &#125; throw nsme; &#125; catch (Exception e) &#123; failedBinding(e); throw new IllegalStateException("Unexpected initialization failure", e); &#125;&#125; 特别要注意的是StaticLoggerBinder.getSingleton();这行代码，StaticLoggerBinder在logback-classic和slf4j-log4j12这两个jar包各有一个，因此，Spring boot是自动选择logback-classic（虽然我在本地运行的时候还是默认进入的slf4j-log4j12，但是会提醒我Source code does not match the bytecode，因此我判断依旧进的是logback-classic），所以只要把logback给exclude掉，就解决了这个问题。 现在看问题，更加关注源代码，因为这可以让我们更加快速定位问题，并且也能据此大致猜出其解决方案。希望大家能一起看看源代码，如果你有什么发现，可以在下方留言，我将和你一起讨论。]]></content>
      <tags>
        <tag>log4j</tag>
        <tag>Spring Boot</tag>
        <tag>logback</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty 心跳相关(1)]]></title>
    <url>%2F2018%2F10%2F23%2FNetty-%E5%BF%83%E8%B7%B3%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[无论是B/S还是C/S架构，如果你用的是长连接，那么心跳是必不可少的。Netty提供了对心跳机制的天然支持，今天结合例子特地学习了一下。 首先，我们来设想一下何时需要发送心跳。假设你做的是一款棋牌类小游戏，那么当玩家登陆游戏后肯定是先进入大厅，再选择一张合适的桌子正式开始游戏。此时玩家的客户端与服务器建立的这一次session（会话）应该是长久保持着，如果服务器端保存着大量的session，那么整个服务器就会越来越卡，最终整个服务都会挂掉。 为了预防这种情况，我们需要清理掉一些已经不用的或者理论上不会再用的session，比如：在手机上，如果我们在游戏中，突然接到一个电话或者退回桌面，这个时候我们的游戏客户端理论上就不会再主动向我们发送任何消息。这时候，心跳就派上用场了。 心跳，是为了证明自己还活着。因此，这里的心跳，说白了就是客户端向服务器端发送一次请求，服务器端相应，这样客户端就知道了服务器端是alive(活着的)；服务器端向客户端发送一次心跳，客户端相应，这样服务器端就知道了客户端是alive。 知道了心跳的大致概念，那现在我们就需要知道Netty中是如何实现心跳，这就引出了两个类：IdleStateHandler、ChannelInboundHandlerAdapter IdleStateHandler大致作用 当连接的空闲时间（无论是读或者是写）太长时，都会触发IdleStateEvent事件。你可以写一个类继承ChannelInboundHandlerAdapter，重写userEventTriggered方法，来处理这类空闲事件。 知道了其大致作用，那么接下来就看看我们到底该如何使用了。 IdleStateHandler有3个构造方法，主要针对这4个属性，分别是：1234private final boolean observeOutput;// 是否考虑出站时较慢的情况。默认值是false（一般不考虑）。private final long readerIdleTimeNanos; // 读事件空闲时间，0 代表禁用事件private final long writerIdleTimeNanos;// 写事件空闲时间，0 代表禁用事件private final long allIdleTimeNanos; //读或写空闲时间，0 代表禁用事件 上面的三个时间，默认是秒，你也可以在构造的时候指定。 当你在pipeline中加入了该handler之后： pipeline.addLast(new IdleStateHandler(30, 90, 0)); // 这个代表只考虑读空闲30秒或写空闲90秒的情况 则会先调用handlerAdded方法：1234567891011@Overridepublic void handlerAdded(ChannelHandlerContext ctx) throws Exception &#123; if (ctx.channel().isActive() &amp;&amp; ctx.channel().isRegistered()) &#123; // channelActive() event has been fired already, which means this.channelActive() will // not be invoked. We have to initialize here instead. initialize(ctx); &#125; else &#123; // channelActive() event has not been fired yet. this.channelActive() will be invoked // and initialization will occur there. &#125;&#125; 如果channel正常，则调用initialize方法：1234567891011121314151617181920212223242526272829private byte state; // 0 - none, 1 - initialized, 2 - destroyedprivate void initialize(ChannelHandlerContext ctx) &#123; // Avoid the case where destroy() is called before scheduling timeouts. // See: https://github.com/netty/netty/issues/143 switch (state) &#123; case 1: // 避免重复添加 case 2: // 如果处于destoryed状态，则不需要添加 return; &#125; state = 1; initOutputChanged(ctx); lastReadTime = lastWriteTime = ticksInNanos(); // 当前时间 // 添加相应的定时调度任务 if (readerIdleTimeNanos &gt; 0) &#123; // readerIdleTimeNanos时间后，执行ReaderIdleTimeoutTask里面的方法 readerIdleTimeout = schedule(ctx, new ReaderIdleTimeoutTask(ctx), readerIdleTimeNanos, TimeUnit.NANOSECONDS); &#125; if (writerIdleTimeNanos &gt; 0) &#123; writerIdleTimeout = schedule(ctx, new WriterIdleTimeoutTask(ctx), writerIdleTimeNanos, TimeUnit.NANOSECONDS); &#125; if (allIdleTimeNanos &gt; 0) &#123; allIdleTimeout = schedule(ctx, new AllIdleTimeoutTask(ctx), allIdleTimeNanos, TimeUnit.NANOSECONDS); &#125;&#125; ReaderIdleTimeoutTask、WriterIdleTimeoutTask、AllIdleTimeoutTask均继承自类AbstractIdleTask12345678910111213141516171819private abstract static class AbstractIdleTask implements Runnable &#123; private final ChannelHandlerContext ctx; AbstractIdleTask(ChannelHandlerContext ctx) &#123; this.ctx = ctx; &#125; @Override public void run() &#123; if (!ctx.channel().isOpen()) &#123; return; &#125; run(ctx); &#125; // 子类需要实现的方法 protected abstract void run(ChannelHandlerContext ctx);&#125; 以ReaderIdleTimeoutTask为例：12345678910111213141516171819202122232425262728293031323334private final class ReaderIdleTimeoutTask extends AbstractIdleTask &#123; ReaderIdleTimeoutTask(ChannelHandlerContext ctx) &#123; super(ctx); &#125; @Override protected void run(ChannelHandlerContext ctx) &#123; long nextDelay = readerIdleTimeNanos; if (!reading) &#123; // 如果不在读(channelRead时会被置为true，cahnnelReadComplete时会被置为false) nextDelay -= ticksInNanos() - lastReadTime; &#125; if (nextDelay &lt;= 0) &#123; // 说明读空闲时间达到或超过预设时间 // Reader is idle - set a new timeout and notify the callback. readerIdleTimeout = schedule(ctx, this, readerIdleTimeNanos, TimeUnit.NANOSECONDS); // firstReaderIdleEvent，是否是第一次读空闲事件(该标志位会在下一次channelRead触发时改成true，所以应该理解在一次读取完成后，这个读空闲事件是不是第一次) boolean first = firstReaderIdleEvent; firstReaderIdleEvent = false; try &#123; // 生成一个IdleStateEvent对象 IdleStateEvent event = newIdleStateEvent(IdleState.READER_IDLE, first); // 找到下一个ChannelInboundHandler类（或其子类）的handler，触发其userEventTrigger(可以参考AbstractChannelHandlerContext的fireUserEventTriggered方法) channelIdle(ctx, event); &#125; catch (Throwable t) &#123; ctx.fireExceptionCaught(t); &#125; &#125; else &#123; // 要么正在读，要么读空闲时间小于预设时间 // Read occurred before the timeout - set a new timeout with shorter delay. readerIdleTimeout = schedule(ctx, this, nextDelay, TimeUnit.NANOSECONDS); &#125; &#125;&#125; schedule方法可以理解为将定时调度事件放进一个队列当中（我是在AbstractScheduledEventExecutor里找到的scheduledTaskQueue().add(task);，但这里面的代码我还没看明白，有兴趣的你可以自己研究，研究完后如果有空可在下方评论）。channelIdle(ctx, event)方法时找到下一个ChannelInboundHandler类（或其子类）的handler，因此你写的继承自ChannelInboundHandler的handler，一定要添加在IdleStateHandler的后面，比如：12pipeline.addLast(new IdleStateHandler(30, 90, 0));pipeline.addLast(heartbeatHandler); ChannelInboundHandler它就很简单了，因为上面说了，channelIdle会调用ChannelInboundHandler的userEventTrigger，所以你只要自己写一个类继承ChannelInboundHandler，并重写它的userEventTrigger方法。比如：1234567891011121314151617181920212223242526272829303132// 用Sharable是因为我的每一个pipeline中用的都是同样的handler@Sharablepublic class NettyHeartbeatHandler extends ChannelInboundHandlerAdapter &#123; private final IHeartbeatFactory factory; public NettyHeartbeatHandler(IHeartbeatFactory factory) &#123; Preconditions.checkNotNull(factory); this.factory = factory; &#125; @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; if (!(evt instanceof IdleStateEvent)) &#123; super.userEventTriggered(ctx, evt); return; &#125; IdleStateEvent event = (IdleStateEvent) evt; if (event.state() == IdleState.READER_IDLE) &#123; // 如果是读空闲，则关闭当前会话 ctx.close(); // 此时会触发下一个ChannelOutboundHandler的close方法，你可以在自己写的handler中进行断线操作 &#125; else if (event.state() == IdleState.WRITER_IDLE) &#123; // 如果是写空闲，则向客户端发送心跳请求包，如果客户端不返回心跳相应包，则说明客户端断线，下一次就将触发读空闲事件。这也是为了向客户端证明服务器端alive ctx.writeAndFlush( new BinaryWebSocketFrame( Unpooled.copiedBuffer(factory.getHeartbeatRequest().toByteArray()) ) ); &#125; &#125;&#125; 因此，以上就是关于用Netty实现心跳的简单介绍。其中带大家重点看了服务器端应该在什么情况下发起一次心跳请求，应该是长久没有收到消息时（可能是有业务含义的消息或者是一个心跳包）。如果大家有什么想法可以在下方评论。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitalk Error: Validation Failed]]></title>
    <url>%2F2018%2F09%2F30%2Fgitalk%20Error%20Validation%20Failed%2F</url>
    <content type="text"><![CDATA[我现在博客的评论系统用的是gitalk，网上教程有很多，我参考的是这份教程。 当我按照网上的说法搭好后，确实是可以利用issue进行评论了，但我在新发表文章时，竟然报错了： 当时我心里一凉，难道和gitment一样，gitalk也凉了？后来上网查了一下，发现是github现在要求issue的label name不能超过50。（奥，现在我才知道，原来gitalk应该是利用label进行筛选，取得当前评论所属的issus。但后来看了一下gitalk的源代码和github关于issue的api，issue的查找应该和你的number有关，而gitalk是当你没有number时就用id代替，看的有点晕。PS：本人在前端方面纯属小白） 好了，那就想想有什么办法可以保证名字的长度可以不超过50吧。没错，就是md5,加密过后都是32位长度，且唯一。当然了，这个也是在gitalk的issue里查到的，接下来就来看看具体应该怎么做吧。 找到js版的md5算法首推的自然是别人已经造好的成熟的轮子，JavaScript-MD5这个应该是可以的，亲测有效。 你只要在你的主题(比如我的就是next)下的source\js\src目录中创放入md5.js.min文件即可。 修改gitalk.swig文件原本你的文件内容应该是：12345678910111213141516&#123;% if page.comments &amp;&amp; theme.gitalk.enable %&#125; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://unpkg.com/gitalk/dist/gitalk.css&quot;&gt; &lt;script src=&quot;https://unpkg.com/gitalk/dist/gitalk.min.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; var gitalk = new Gitalk(&#123; clientID: &apos;&#123;&#123; theme.gitalk.ClientID &#125;&#125;&apos;, clientSecret: &apos;&#123;&#123; theme.gitalk.ClientSecret &#125;&#125;&apos;, repo: &apos;&#123;&#123; theme.gitalk.repo &#125;&#125;&apos;, owner: &apos;&#123;&#123; theme.gitalk.githubID &#125;&#125;&apos;, admin: [&apos;&#123;&#123; theme.gitalk.adminUser &#125;&#125;&apos;], id: location.pathname, distractionFreeMode: &apos;&#123;&#123; theme.gitalk.distractionFreeMode &#125;&#125;&apos; &#125;) gitalk.render(&apos;gitalk-container&apos;) &lt;/script&gt;&#123;% endif %&#125; 现在改成即可(修改了第4行和第12行)1234567891011121314151617&#123;% if page.comments &amp;&amp; theme.gitalk.enable %&#125; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://unpkg.com/gitalk/dist/gitalk.css&quot;&gt; &lt;script src=&quot;https://unpkg.com/gitalk/dist/gitalk.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;/js/src/md5.min.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; var gitalk = new Gitalk(&#123; clientID: &apos;&#123;&#123; theme.gitalk.ClientID &#125;&#125;&apos;, clientSecret: &apos;&#123;&#123; theme.gitalk.ClientSecret &#125;&#125;&apos;, repo: &apos;&#123;&#123; theme.gitalk.repo &#125;&#125;&apos;, owner: &apos;&#123;&#123; theme.gitalk.githubID &#125;&#125;&apos;, admin: [&apos;&#123;&#123; theme.gitalk.adminUser &#125;&#125;&apos;], id: md5(location.pathname), distractionFreeMode: &apos;&#123;&#123; theme.gitalk.distractionFreeMode &#125;&#125;&apos; &#125;) gitalk.render(&apos;gitalk-container&apos;) &lt;/script&gt;&#123;% endif %&#125; 然后重新发布就ok了，gitalk又可以正确创建issue了，你又可以继续评论了。 需要注意的问题因为gitalk关联issue是通过number，你没有number的时候，它会直接利用你的id，而id的这个生成条件又被你修改了，因此你之前评论是无法和你的文章关联上了。如果对js稍微感兴趣的话，应该可以顺着这个思路往下能解决。博主有空也会试试，就当研究研究js，大家要是有成功的案例，可以在通过评论告知，毕竟这也是造福大家。附上gitalk源码地址。]]></content>
      <categories>
        <category>解决问题</category>
      </categories>
      <tags>
        <tag>gitalk</tag>
        <tag>Error</tag>
        <tag>Validation Failed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos6安装shadowsocks及配置]]></title>
    <url>%2F2018%2F09%2F30%2FCentos6%E5%AE%89%E8%A3%85shadowsocks%E5%8F%8A%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[买下搬瓦工的服务器，很多人首先会希望配置多个端口方便使用，这时候就需要安装shadowsocks来解决。现在我来介绍一下Centos6系统下shadowsocks的安装及配置过程。 这篇文章原是我在CSDN上发表的一篇博客，但在去年年底时莫名其妙被删除了，因此在这里，我把文章搬运过来，也是方便自己查看里面的一些命令。 这是一个搬瓦工的购买教程网站 安装python、pip、shadowsocks安装python： yum install python-setuptools 安装wget yum install wget 安装pip：（先下载再安装）1234wget https://pypi.python.org/packages/source/p/pip/pip-1.3.1.tar.gz --no-check-certificatetar -xzvf pip-1.3.1.tar.gzcd pip-1.3.1python setup.py install 安装shadowsocks pip install shadowsocks 配置shadowsocks首先创建配置文件/etc/shadowsocks.json touch /etc/shadowsocks.json 创建并编辑shadowsocks.json vi /etc/shadowsocks.json 现在要决定你是否需要开多端口，因为开出多个端口，每个端口的速度影响不大，但如果用同一个端口，速度会有所影响。 shadowsocks.json内容为：123456789101112&#123; &quot;server&quot;:&quot;你的IP地址&quot;, &quot;local_address&quot;: &quot;127.0.0.1&quot;, &quot;local_port&quot;:1080, &quot;port_password&quot;:&#123; &quot;端口号1&quot;:&quot;密码1&quot;, &quot;端口号2&quot;:&quot;密码2&quot; &#125;, &quot;timeout&quot;:600, &quot;method&quot;:&quot;rc4-md5&quot;, &quot;fast_open&quot;: false&#125; 对应你本地的shadowsocks配置为： 这时可以在Centos上运行shadowsocks服务： ssserver -c /etc/shadowsocks.json -d start 此时理论上你就可以科学上网了。 停止shadowsocks服务命令： ssserver -c /etc/shadowsocks.json -d stop 可能遇到的问题当你设置好配置文件并且启动之后，发现本地并不能上外网，其实可以通过shadowsocks的更新PAC功能查看是否可以连接外网： 如果更新失败，则代表无法连接外网，这时候请看一下你的服务器上设置的端口是否开启： netstat -ntlp 我开启了443、7788、7789、7790四个端口，如果你发现此处没有你的端口号，代表端口未打开 此时你需要先关闭shadowsocks，使用关闭命令，然后打开你所需要的端口。 利用iptables打开端口命令: /sbin/iptables -I INPUT -p tcp --dport 端口号 -j ACCEPT 保存你刚刚添加的规则: /etc/rc.d/init.d/iptables save 查看打开的端口： /etc/init.d/iptables status 现在这里会显示出你刚刚打开的端口。 现在开启你服务器上的shadowsocks，再用查看端口命令，应该就显示出你的端口已经打开了。 资源下载shadowsocks相关下载包安卓版本官方下载电脑版Windows 7及之前的版本电脑版Windows 8及之后的版本iOS教程]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初章]]></title>
    <url>%2F2018%2F09%2F29%2F%E5%88%9D%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[第一次使用hexo写博客，希望能有一个不错的开始。]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
</search>
