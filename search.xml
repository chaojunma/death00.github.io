<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Java服务器获取客户端的真实IP]]></title>
    <url>%2F2018%2F11%2F12%2FJava%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%8E%B7%E5%8F%96%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84%E7%9C%9F%E5%AE%9EIP%2F</url>
    <content type="text"><![CDATA[在进行一些小游戏开发时，我们经常比较关注的一个功能便是分享。针对分享，我们希望能根据各个城市或者地区，能有不同的分享文案，辨识地区的功能如果由服务器来完成的话，我们就需要知道客户端的真实IP。今天我们就来看看服务器是如何获取到客户端的真实IP的。 nginx配置首先，一个请求肯定是可以分为请求头和请求体的，而我们客户端的IP地址信息一般都是存储在请求头里的。如果你的服务器有用Nginx做负载均衡的话，你需要在你的location里面配置X-Real-IP和X-Forwarded-For请求头： 12345location ^~ /your-service/ &#123; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://localhost:60000/your-service/;&#125; X-Real-IP在《实战nginx》中，有这么一句话：1经过反向代理后，由于在客户端和web服务器之间增加了中间层，因此web服务器无法直接拿到客户端的ip，通过$remote_addr变量拿到的将是反向代理服务器的ip地址。 这句话的意思是说，当你使用了nginx反向服务器后，在web端使用request.getRemoteAddr()（本质上就是获取$remote_addr），取得的是nginx的地址，即$remote_addr变量中封装的是nginx的地址，当然是没法获得用户的真实ip的。但是，nginx是可以获得用户的真实ip的，也就是说nginx使用$remote_addr变量时获得的是用户的真实ip，如果我们想要在web端获得用户的真实ip，就必须在nginx里作一个赋值操作，即我在上面的配置：1proxy_set_header X-Real-IP $remote_addr; X-Forwarded-ForX-Forwarded-For变量，这是一个squid开发的，用于识别通过HTTP代理或负载平衡器原始IP一个连接到Web服务器的客户机地址的非rfc标准，如果有做X-Forwarded-For设置的话,每次经过proxy转发都会有记录,格式就是client1,proxy1,proxy2以逗号隔开各个地址，由于它是非rfc标准，所以默认是没有的，需要强制添加。在默认情况下经过proxy转发的请求，在后端看来远程地址都是proxy端的ip 。也就是说在默认情况下我们使用request.getAttribute(&quot;X-Forwarded-For&quot;)获取不到用户的ip，如果我们想要通过这个变量获得用户的ip，我们需要自己在nginx添加配置：1proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 意思是增加一个$proxy_add_x_forwarded_for到X-Forwarded-For里去，注意是增加，而不是覆盖，当然由于默认的X-Forwarded-For值是空的，所以我们总感觉X-Forwarded-For的值就等于$proxy_add_x_forwarded_for的值，实际上当你搭建两台nginx在不同的ip上，并且都使用了这段配置，那你会发现在web服务器端通过request.getAttribute(&quot;X-Forwarded-For&quot;)获得的将会是客户端ip和第一台nginx的ip。 那么$proxy_add_x_forwarded_for又是什么？ $proxy_add_x_forwarded_for变量包含客户端请求头中的X-Forwarded-For与$remote_addr两部分，他们之间用逗号分开。 举个例子，有一个web应用，在它之前通过了两个nginx转发，www.linuxidc.com即用户访问该web通过两台nginx。 在第一台nginx中,使用： 1proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 现在的$proxy_add_x_forwarded_for变量的X-Forwarded-For部分是空的，所以只有$remote_addr，而$remote_addr的值是用户的ip，于是赋值以后，X-Forwarded-For变量的值就是用户的真实的ip地址了。 到了第二台nginx，使用：1proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 现在的$proxy_add_x_forwarded_for变量，X-Forwarded-For部分包含的是用户的真实ip，$remote_addr部分的值是上一台nginx的ip地址，于是通过这个赋值以后现在的X-Forwarded-For的值就变成了“用户的真实ip，第一台nginx的ip”，这样就清楚了吧。 服务器获取真实IP代码为： 12345678910111213141516171819202122232425262728293031323334public static String getIpAddress(HttpServletRequest request) &#123; String Xip = request.getHeader("X-Real-IP"); String XFor = request.getHeader("X-Forwarded-For"); if (!Strings.isNullOrEmpty(XFor) &amp;&amp; !"unKnown".equalsIgnoreCase(XFor)) &#123; //多次反向代理后会有多个ip值，第一个ip才是真实ip int index = XFor.indexOf(","); if (index != -1) &#123; return XFor.substring(0, index); &#125; else &#123; return XFor; &#125; &#125; XFor = Xip; if (!Strings.isNullOrEmpty(XFor) &amp;&amp; !"unKnown".equalsIgnoreCase(XFor)) &#123; return XFor; &#125; if (Strings.nullToEmpty(XFor).trim().isEmpty() || "unknown".equalsIgnoreCase(XFor)) &#123; XFor = request.getHeader("Proxy-Client-IP"); &#125; if (Strings.nullToEmpty(XFor).trim().isEmpty() || "unknown".equalsIgnoreCase(XFor)) &#123; XFor = request.getHeader("WL-Proxy-Client-IP"); &#125; if (Strings.nullToEmpty(XFor).trim().isEmpty() || "unknown".equalsIgnoreCase(XFor)) &#123; XFor = request.getHeader("HTTP_CLIENT_IP"); &#125; if (Strings.nullToEmpty(XFor).trim().isEmpty() || "unknown".equalsIgnoreCase(XFor)) &#123; XFor = request.getHeader("HTTP_X_FORWARDED_FOR"); &#125; if (Strings.nullToEmpty(XFor).trim().isEmpty() || "unknown".equalsIgnoreCase(XFor)) &#123; XFor = request.getRemoteAddr(); &#125; return XFor;&#125; 我们来看看各个请求头的含义 X-Real-IPnginx代理一般会加上此请求头。 X-FORWARDED-FOR这是一个Squid开发的字段，只有在通过了HTTP代理或者负载均衡服务器时才会添加该项。 Proxy-Client-IP 和 WL-Proxy-Client-IP这个一般是经过apache http服务器的请求才会有，用apache http做代理时一般会加上Proxy-Client-IP请求头，而WL-Proxy-Client-IP是它的weblogic插件加上的头。 HTTP_CLIENT_IP有些代理服务器会加上此请求头。在网上搜了一下，有一个说法是：123456789101112这是普通的 http header，伪造起来很容易，不要轻易信任用户输入。 curl -H &apos;client-ip: 8.8.8.8&apos; lidian.club/phpinfo.php | grep _SERVER 你就能看到 _SERVER[&quot;HTTP_CLIENT_IP&quot;] 了。 client-ip 和 client-host 是在 NAPT 还没普及的年代，企业内网假设的 http 透明代理，传给服务器的 header，只有极少数厂家用过，从来不是标准，也从来没成为过事实标准。 （大家最熟悉的事实标准就是 x-forwarded-for） 后来出现的 web proxy 也没见用过这个 header。 TCP/IP Illustrated Vol 3 没有讲过这个 header，网上的传言不可信。 可考的最早痕迹出现在2005年，日本一部 Perl/CGI 秘籍（9784798010779，270页）通过 client-ip 与 via 两个 header 屏蔽代理用户访问。 HTTP_X_FORWARDED_FOR简称XFF头，它代表客户端，也就是HTTP的请求端真实的IP，只有在通过了HTTP 代理(比如APACHE代理)或者负载均衡服务器时才会添加该项。它不是RFC中定义的标准请求头信息，在squid缓存代理服务器开发文档中可以找到该项的详细介绍。如果有该条信息, 说明您使用了代理服务器，地址就是后面的数值。可以伪造。标准格式如下：X-Forwarded-For: client1, proxy1, proxy2 总结以上就是我在处理客户端真实IP的方法，如果你有什么意见或者建议，可以在下方留言。]]></content>
      <tags>
        <tag>Java</tag>
        <tag>nginx</tag>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中List的sort源码解读]]></title>
    <url>%2F2018%2F11%2F02%2Fjava%E4%B8%ADList%E7%9A%84sort%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[最近看了一些排序相关的文章，因此比较好奇，Java中的排序是如何做的。本片文章介绍的是JDK1.8，List中的sort方法。 先来看看List中的sort是怎么写的：12345678910@SuppressWarnings(&#123;"unchecked", "rawtypes"&#125;)default void sort(Comparator&lt;? super E&gt; c) &#123; Object[] a = this.toArray(); Arrays.sort(a, (Comparator) c); ListIterator&lt;E&gt; i = this.listIterator(); for (Object e : a) &#123; i.next(); i.set((E) e); &#125;&#125; 首先，你需要传入一个比较器作为参数，这个好理解，毕竟你肯定要定一个比较标准。然后就是将list转换成一个数组，再对这个数组进行排序，排序完之后，再利用iterator重新改变list。 接着，我们再来看看Arrays.sort：123456789101112131415161718192021222324public static &lt;T&gt; void sort(T[] a, Comparator&lt;? super T&gt; c) &#123; if (c == null) &#123; sort(a); &#125; else &#123; if (LegacyMergeSort.userRequested) legacyMergeSort(a, c); else TimSort.sort(a, 0, a.length, c, null, 0, 0); &#125;&#125;public static void sort(Object[] a) &#123; if (LegacyMergeSort.userRequested) legacyMergeSort(a); else ComparableTimSort.sort(a, 0, a.length, null, 0, 0);&#125;static final class LegacyMergeSort &#123; private static final boolean userRequested = java.security.AccessController.doPrivileged( new sun.security.action.GetBooleanAction( "java.util.Arrays.useLegacyMergeSort")).booleanValue();&#125; 这样可以看出，其实排序的核心就是TimSort，LegacyMergeSort大致意思是表明如果版本很旧的话，就用这个，新版本是不会采用这种排序方式的。 我们再来看看TimSort的实现：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849private static final int MIN_MERGE = 32;static &lt;T&gt; void sort(T[] a, int lo, int hi, Comparator&lt;? super T&gt; c, T[] work, int workBase, int workLen) &#123; assert c != null &amp;&amp; a != null &amp;&amp; lo &gt;= 0 &amp;&amp; lo &lt;= hi &amp;&amp; hi &lt;= a.length; int nRemaining = hi - lo; if (nRemaining &lt; 2) return; // Arrays of size 0 and 1 are always sorted // If array is small, do a "mini-TimSort" with no merges if (nRemaining &lt; MIN_MERGE) &#123; // 获得最长的递增序列 int initRunLen = countRunAndMakeAscending(a, lo, hi, c); binarySort(a, lo, hi, lo + initRunLen, c); return; &#125; /** * March over the array once, left to right, finding natural runs, * extending short natural runs to minRun elements, and merging runs * to maintain stack invariant. */ TimSort&lt;T&gt; ts = new TimSort&lt;&gt;(a, c, work, workBase, workLen); int minRun = minRunLength(nRemaining); do &#123; // Identify next run int runLen = countRunAndMakeAscending(a, lo, hi, c); // If run is short, extend to min(minRun, nRemaining) if (runLen &lt; minRun) &#123; int force = nRemaining &lt;= minRun ? nRemaining : minRun; binarySort(a, lo, lo + force, lo + runLen, c); runLen = force; &#125; // Push run onto pending-run stack, and maybe merge ts.pushRun(lo, runLen); ts.mergeCollapse(); // Advance to find next run lo += runLen; nRemaining -= runLen; &#125; while (nRemaining != 0); // Merge all remaining runs to complete sort assert lo == hi; ts.mergeForceCollapse(); assert ts.stackSize == 1;&#125; 如果小于2个，代表不再不需要排序；如果小于32个，则采用优化的二分排序。怎么优化的呢？首先获得最长的递增序列： 123456789101112131415161718192021private static &lt;T&gt; int countRunAndMakeAscending(T[] a, int lo, int hi, Comparator&lt;? super T&gt; c) &#123; assert lo &lt; hi; int runHi = lo + 1; if (runHi == hi) return 1; // Find end of run, and reverse range if descending if (c.compare(a[runHi++], a[lo]) &lt; 0) &#123; // Descending // 一开始是递减序列，就找出最长递减序列的最后一个下标 while (runHi &lt; hi &amp;&amp; c.compare(a[runHi], a[runHi - 1]) &lt; 0) runHi++; // 逆转前面的递减序列 reverseRange(a, lo, runHi); &#125; else &#123; // Ascending while (runHi &lt; hi &amp;&amp; c.compare(a[runHi], a[runHi - 1]) &gt;= 0) runHi++; &#125; return runHi - lo;&#125; 接着进行二分排序：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748private static &lt;T&gt; void binarySort(T[] a, int lo, int hi, int start, Comparator&lt;? super T&gt; c) &#123; assert lo &lt;= start &amp;&amp; start &lt;= hi; if (start == lo) start++; for ( ; start &lt; hi; start++) &#123; T pivot = a[start]; // Set left (and right) to the index where a[start] (pivot) belongs int left = lo; int right = start; assert left &lt;= right; /* * Invariants: * pivot &gt;= all in [lo, left). * pivot &lt; all in [right, start). */ // start位置是递增序列后的第一个数的位置 // 从前面的递增序列中找出start位置的数应该处于的位置 while (left &lt; right) &#123; // &gt;&gt;&gt; 无符号右移 int mid = (left + right) &gt;&gt;&gt; 1; if (c.compare(pivot, a[mid]) &lt; 0) right = mid; else left = mid + 1; &#125; assert left == right; /* * The invariants still hold: pivot &gt;= all in [lo, left) and * pivot &lt; all in [left, start), so pivot belongs at left. Note * that if there are elements equal to pivot, left points to the * first slot after them -- that's why this sort is stable. * Slide elements over to make room for pivot. */ int n = start - left; // The number of elements to move // Switch is just an optimization for arraycopy in default case // 比pivot大的数往后移动一位 switch (n) &#123; case 2: a[left + 2] = a[left + 1]; case 1: a[left + 1] = a[left]; break; default: System.arraycopy(a, left, a, left + 1, n); &#125; a[left] = pivot; &#125;&#125; 好了，待排序数量小于32个的讲完了，现在来说说大于等于32个情况。首先，获得一个叫minRun的东西，这是个啥含义呢：1234567891011int minRun = minRunLength(nRemaining);private static int minRunLength(int n) &#123; assert n &gt;= 0; int r = 0; // Becomes 1 if any 1 bits are shifted off while (n &gt;= MIN_MERGE) &#123; // 这里我没搞懂的是为什么不直接将(n &amp; 1)赋值给r，而要做一次逻辑或。 r |= (n &amp; 1); n &gt;&gt;= 1; &#125; return n + r;&#125; 各种位运算符，MIN_MERGE默认为32，如果n小于此值，那么返回n本身。否则会将n不断地右移，直到小于MIN_MERGE，同时记录一个r值，r代表最后一次移位n时，n最低位是0还是1。其实看注释比较容易理解： 1234Returns the minimum acceptable run length for an array of the specified length. Natural runs shorter than this will be extended with binarySort.Roughly speaking, the computation is: If n &lt; MIN_MERGE, return n (it&apos;s too small to bother with fancy stuff).Else if n is an exact power of 2, return MIN_MERGE/2.Else return an int k, MIN_MERGE/2 &lt;= k &lt;= MIN_MERGE, such that n/k is close to, but strictly less than, an exact power of 2. For the rationale, see listsort.txt. 返回结果其实就是用于接下来的合并排序中。 接下来就是一个while循环1234567891011121314151617181920212223do &#123; // Identify next run // 获得一个最长递增序列 int runLen = countRunAndMakeAscending(a, lo, hi, c); // If run is short, extend to min(minRun, nRemaining) // 如果最长递增序列 if (runLen &lt; minRun) &#123; int force = nRemaining &lt;= minRun ? nRemaining : minRun; binarySort(a, lo, lo + force, lo + runLen, c); runLen = force; &#125; // Push run onto pending-run stack, and maybe merge // lo——runLen为将要被归并的范围 ts.pushRun(lo, runLen); // 归并 ts.mergeCollapse(); // Advance to find next run lo += runLen; nRemaining -= runLen;&#125; while (nRemaining != 0); 这样，假设你的每次归并排序的两个序列为r1和r2，r1肯定是有序的，r2也已经被排成递增序列了，因此这样的归并排序就比较特殊了。 为什么要用归并排序呢，因为归并排序的时间复杂度永远为O(nlogn)，空间复杂度为O(n)，以空间换取时间。 好了，以上就是针对Java中的排序做的一次总结，但具体的归并代码还没有分析，其实我自己也没有完全研究透，为什么minRun的取值是这样的，这也和TimSort中的stackLen有关，有兴趣的小伙伴可以在下方留言，我们可以一起探讨。]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DDL-脏数据层的实现]]></title>
    <url>%2F2018%2F10%2F31%2FDDL-%E8%84%8F%E6%95%B0%E6%8D%AE%E5%B1%82%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[在我们的项目中，经常会有一些数据会涉及到频繁更改。如果每次都从数据库中读取再修改，这样不仅浪费时间，而且还更加危险。那此时我们究竟该如何解决这个问题呢？此时，DDL(脏数据层)就出现了。 首先说一下为什么操作不能保证原子性就会危险，因为这时就很有可能出现同时修改的情况，最终的结果极有可能并不是你所希望的（除非这些操作都是幂等性，但这种情况应该比较少）。如果是利用数据库中的锁，一来我在项目中用的比较少，二来也增加了维护难度。当然，有人说可以利用CAS，那针对一些复杂的情况（比如类里面属性的修改会有一些相关性，你的一次更改需要涉及几个属性等），可能你还是需要单独设计一套系统，而且还会有经典的ABA问题。如果你是利用CAS解决的，希望能够在下方评论区告知，就当互相学习。 那现在来说说DDL层具体是什么。DDL全称是Dirty Data Layer，即脏数据层。针对那些在系统运行经常会更改的domain类，我们将其再做一次封装，组成一个类似map的形式。单独由一组线程来管理这些map，每当有数据改动时，我们就往这个map中添加内容，而我们的线程则定期向数据库中写入内容。这样做的好处，首先是让你的每一次操作都没有IO的参与，提高了相应速度，而且定时提交意味着你可以把原本的几次提交变成为1次，减少了和数据库的交互。当然，缺点也是存在的，如果你的系统是分布式，那么你的这个DDL层的实现可能就没有那么方便，因为这些数据你可能需要存储在类似Redis这种共享缓存中，因此每次的拿和取就需要封装一下（这个应该算是小问题，因为原本就算你用的是本地缓存，所有操作依旧是需要封装的，只不过你的IO消耗由原本的数据库变成了共享缓存）。接下来，我就针对本地缓存的情况来具体实现一个DDL。 定义操作这是我定义出的一些操作：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118public interface IDirtyEntity &#123; //region manage content /** * 获取entity的内容。 */ Object getContent(); /** * 获取entity的内容。 获取的内容是复制的对象，属性值是调用该方法时的属性值。 */ Object copyContent(); //endregion //region persisting flag /** * 是否正在进行持久化 */ boolean isPersisting(); /** * 设置正在持久化标志 */ void setPersistingFlag(); /** * 清除正在持久化标志 */ void clearPersistingFlag(); //endregion //region persist state /** * 设置为脏数据状态 */ void setDirtyState(); /** * 清除脏数据状态 */ void clearDirtyState(); /** * 当前持久化状态。 * * @see PersistState */ PersistState currentPersistState(); //endregion //region get/set field /** * 获取属性值。 */ Object getField(String fieldName); /** * 设置属性值。 */ void setField(String fieldName, Object value); /** * 设置多个属性的值。 */ void setFields(List&lt;EntityField&gt; fields); /** * 增加int类型属性的值。 */ void addInt(String fieldName, int delta); /** * 增加long类型属性的值。 */ void addLong(String fieldName, long delta); //endregion //region manage dirty field /** * 标记脏数据字段 */ void addDirtyField(String fieldName); /** * 获取修改过的属性。 */ List&lt;EntityField&gt; getAndClearDirtyFields(); //endregion //region wrapper implement /** * 返回id的属性名。 */ String getIdFieldName(); /** * 返回id */ String getId(); /** * 返回DATA的class */ Class getDataClass(); //endregion&#125; 分类DDL解决的是数据频繁更改的问题，其实这里的更改说的并不准确，并不仅仅只是update，还有insert。用过mongodb的应该清楚有一种叫upsert的操作，就是找到就修改，找不到就添加。我们这里就需要将我们的数据分成两类：Detachable(可拆分的)、Nondetachable(不可拆分的)。 可拆分的，就意味着你针对这个数据的修改最小可以精确到其中的一个属性，项目中大多数都属于这种情况。 不可拆分的，即每次都是以一个整体添加，比如一次交易，每次添加都是一个整体，不可能说你先提交买方，再提交卖方，后面还会修改买方。这种类型大多都是一条记录，整体存入数据库。 因此，我们来定义一下这两种结构：可拆分的类型：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183import com.google.common.base.Preconditions;import com.google.common.base.Strings;import java.util.List;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.cglib.beans.BeanCopier;import org.springframework.cglib.beans.BeanMap;public abstract class DetachableDirtyEntityAdapter implements IDirtyEntity &#123; private static final Logger log = LoggerFactory.getLogger(DetachableDirtyEntityAdapter.class); /** * 数据属性的map引用 */ private BeanMap beanMap; private final BeanCopier beanCopier; public DetachableDirtyEntityAdapter(Object content, BeanCopier beanCopier) &#123; Preconditions.checkNotNull(content); Preconditions.checkNotNull(beanCopier); this.content = newEmptyContentInstance(); this.beanCopier = beanCopier; this.beanCopier.copy(content, this.content, null); this.beanMap = BeanMap.create(this.content); &#125; //region manage content /** * 数据的内容。 */ private Object content; @Override public Object getContent() &#123; return content; &#125; private Object newEmptyContentInstance() &#123; Class cls = getDataClass(); try &#123; return cls.newInstance(); &#125; catch (Exception e) &#123; log.error("initiate &#123;&#125; failed: &#123;&#125;", cls.getSimpleName(), e.getMessage()); return null; &#125; &#125; @Override public synchronized Object copyContent() &#123; Object copy = newEmptyContentInstance(); beanCopier.copy(this.content, copy, null); return copy; &#125; //endregion //region persisting flag private volatile boolean persisting = false; @Override public boolean isPersisting() &#123; return persisting; &#125; @Override public void setPersistingFlag() &#123; this.persisting = true; &#125; @Override public void clearPersistingFlag() &#123; this.persisting = false; &#125; //endregion //region persist state @Override public void setDirtyState() &#123; throw new UnsupportedOperationException(); &#125; @Override public void clearDirtyState() &#123; throw new UnsupportedOperationException(); &#125; @Override public synchronized PersistState currentPersistState() &#123; int dirtySize = dirtyFieldNames.size(); if (dirtySize == 0) &#123; return PersistState.PERSISTED; &#125; else &#123; return PersistState.DIRTY; &#125; &#125; //endregion //region get/set field @Override public synchronized Object getField(String fieldName) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); return beanMap.get(fieldName); &#125; @Override public synchronized void setField(String fieldName, Object value) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); beanMap.put(fieldName, value); dirtyFieldNames.add(fieldName); &#125; @Override public synchronized void setFields(List&lt;EntityField&gt; fields) &#123; Preconditions.checkNotNull(fields); for (EntityField f : fields) &#123; beanMap.put(f.getName(), f.getValue()); dirtyFieldNames.add(f.getName()); &#125; &#125; @Override public synchronized void addInt(String fieldName, int delta) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); int origin = (int) beanMap.get(fieldName); beanMap.put(fieldName, origin + delta); dirtyFieldNames.add(fieldName); &#125; @Override public synchronized void addLong(String fieldName, long delta) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); long origin = (long) beanMap.get(fieldName); beanMap.put(fieldName, origin + delta); dirtyFieldNames.add(fieldName); &#125; //endregion //region manage dirty fields /** * 当前entity的包含脏数据的属性名列表。 */ private final HashSet&lt;String&gt; dirtyFieldNames = new HashSet&lt;&gt;(16); @Override public void addDirtyField(String fieldName) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); dirtyFieldNames.add(fieldName); &#125; @Override public synchronized List&lt;EntityField&gt; getAndClearDirtyFields() &#123; ArrayList&lt;EntityField&gt; list = new ArrayList&lt;&gt;(); for (String f : dirtyFieldNames) &#123; list.add(new EntityField(f, beanMap.get(f))); &#125; // 清空dirtyFieldNames, 记录上一次持久化的事件 dirtyFieldNames.clear(); return list; &#125; //endregion&#125; 不可拆分的类型：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161import com.google.common.base.Preconditions;import com.google.common.base.Strings;import java.util.ArrayList;import java.util.HashSet;import java.util.List;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.cglib.beans.BeanCopier;import org.springframework.cglib.beans.BeanMap;public abstract class NonDetachableDirtyEntityAdapter implements IDirtyEntity &#123; private static final Logger log = LoggerFactory.getLogger(NonDetachableDirtyEntityAdapter.class); /** * 数据属性的map引用 */ private BeanMap beanMap; private final BeanCopier beanCopier; public NonDetachableDirtyEntityAdapter(Object content, BeanCopier beanCopier) &#123; Preconditions.checkNotNull(content); Preconditions.checkNotNull(beanCopier); this.content = newEmptyContentInstance(); this.beanCopier = beanCopier; this.beanCopier.copy(content, this.content, null); this.beanMap = BeanMap.create(this.content); &#125; //region manage content /** * 数据的内容。 */ private Object content; @Override public Object getContent() &#123; return content; &#125; private Object newEmptyContentInstance() &#123; Class cls = getDataClass(); try &#123; return cls.newInstance(); &#125; catch (Exception e) &#123; log.error("initiate &#123;&#125; failed: &#123;&#125;", cls.getSimpleName(), e.getMessage()); return null; &#125; &#125; @Override public synchronized Object copyContent() &#123; Object copy = newEmptyContentInstance(); beanCopier.copy(this.content, copy, null); return copy; &#125; //endregion //region persisting flag private volatile boolean persisting = false; @Override public boolean isPersisting() &#123; return persisting; &#125; @Override public void setPersistingFlag() &#123; this.persisting = true; &#125; @Override public void clearPersistingFlag() &#123; this.persisting = false; &#125; //endregion //region persist state private volatile PersistState persistState = PersistState.DIRTY; @Override public void setDirtyState() &#123; persistState = PersistState.DIRTY; &#125; @Override public void clearDirtyState() &#123; persistState = PersistState.PERSISTED; &#125; @Override public PersistState currentPersistState() &#123; return persistState; &#125; //endregion //region get/set field @Override public synchronized Object getField(String fieldName) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); return beanMap.get(fieldName); &#125; @Override public synchronized void setField(String fieldName, Object value) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); beanMap.put(fieldName, value); &#125; @Override public synchronized void setFields(List&lt;EntityField&gt; fields) &#123; Preconditions.checkNotNull(fields); for (EntityField f : fields) &#123; beanMap.put(f.getName(), f.getValue()); &#125; &#125; @Override public synchronized void addInt(String fieldName, int delta) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); int origin = (int) beanMap.get(fieldName); beanMap.put(fieldName, origin + delta); &#125; @Override public synchronized void addLong(String fieldName, long delta) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); long origin = (long) beanMap.get(fieldName); beanMap.put(fieldName, origin + delta); &#125; //endregion //region manage dirty fields @Override public void addDirtyField(String fieldName) &#123; throw new UnsupportedOperationException(); &#125; @Override public synchronized List&lt;EntityField&gt; getAndClearDirtyFields() &#123; throw new UnsupportedOperationException(); &#125; //endregion&#125; 两种类型最大的不同在于真正往数据库中存储时，前者是可以单独字段存储，后者是整体存储，因此最后和DirtyField相关的操作便需要注意，NondetachableDirtyEntityAdapter不需要记录DirtyFields。 针对原本类中属性的复制和存储，我这儿用的是spring提供的BeanCopier，如果你有什么更高效的工具，欢迎在下方留言。（我一直在找一种深度克隆高效的组件，试过kryo，但如果实现序列化接口，其效率和正常的set/get大概相差10倍，如果有好的组件，希望一并告知）。 以上就是DDL的准备工作，其实后面的工作就是将具体的类做一个封装，再封装针对该类的所有操作，然后另写一个线程组执行往数据库的写入操作。这个工作其实针对各个项目都有其特殊的地方，博主在这儿就不具体展示了，有兴趣的话大家可以在下方留言。]]></content>
      <categories>
        <category>DDL</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[log4j日志不输出的问题]]></title>
    <url>%2F2018%2F10%2F24%2Flog4j%E6%97%A5%E5%BF%97%E4%B8%8D%E8%BE%93%E5%87%BA%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[今天服务器上报错，想先去看一下日志进行排查，结果发现日志很久都没有输出过了。从上午排查到下午，刚刚解决，因此记录一下，但现在也只是知其然，并不知其所以然，所以如果大家有什么想法请在下方评论。 先说一下环境，服务器是linux，项目是运行在tomcat下的Spring项目，日志用的是log4j。 首先，从10月13号开始便没有新的日志文件了。假设日志名为log.txt（如果你设置了DailyRollingFileAppender，那么你当天的日志文件就是log.txt），先备份该文件到其他目录下，然后删除该文件，重新启动tomcat。这是为了确认你的log4j配置是否有问题，因为这是最容易出错的地方。很遗憾，我不是这里出的问题，因为项目重启后，日志文件又重新生成了，但很奇怪的是，日志文件是空的，其大小为0. 感觉自己碰上了很神奇的问题，因此我在自己的本地进行调试，启动项目后发现，正常的项目启动日志是有的：115:13:48:0253 INFO [RMI TCP Connection(3)-127.0.0.1] -Root WebApplicationContext: initialization completed in 18479 ms 但我自己的一些日志输出是不显示的，比如：12private static final Logger log = LoggerFactory.getLogger(MyDomain.class);log.info("show info log"); show info log这句话就不打印，现在证明，我的日志配置没有问题，服务器也找到了我的日志文件，但应该是我自己的Logger是不对应正确的日志输出的，因为我的console(控制台)有显示。 接下来，我就是开始看源码了。先是LoggerFactory.getLogger(Class&lt;?&gt; clazz)方法：123456789101112public static Logger getLogger(Class&lt;?&gt; clazz) &#123; Logger logger = getLogger(clazz.getName()); if (DETECT_LOGGER_NAME_MISMATCH) &#123; Class&lt;?&gt; autoComputedCallingClass = Util.getCallingClass(); if (autoComputedCallingClass != null &amp;&amp; nonMatchingClasses(clazz, autoComputedCallingClass)) &#123; Util.report(String.format("Detected logger name mismatch. Given name: \"%s\"; computed name: \"%s\".", logger.getName(), autoComputedCallingClass.getName())); Util.report("See " + LOGGER_NAME_MISMATCH_URL + " for an explanation"); &#125; &#125; return logger;&#125; 好吧，没什么用，看不出我的logger变成了，继续看getLogger(String name)方法：1234public static Logger getLogger(String name) &#123; ILoggerFactory iLoggerFactory = getILoggerFactory(); return iLoggerFactory.getLogger(name);&#125; 这时我在return iLoggerFactory.getLogger(name);这行打了断点，我看到了这样的东西： 为什么我的iLoggerFactory是用的logback中的实现？其实也是怪我自己大意，我其实依赖了一个基于Spring Boot的项目(虽然我只是用了里面的一些domain类，但因为设计不当，还没有把这些domain类单独提成一个_项目)，而Spring Boot中一般默认就依赖的logback。通过gradle查看项目的依赖树，也证实了我的这一猜想(./gradlew 子项目名称:dependencies):1234567891011| +--- org.springframework.boot:spring-boot-starter-web:2.0.2.RELEASE| | +--- org.springframework.boot:spring-boot-starter:2.0.2.RELEASE| | | +--- org.springframework.boot:spring-boot:2.0.2.RELEASE| | | | +--- org.springframework:spring-core:5.0.6.RELEASE (*)| | | | \--- org.springframework:spring-context:5.0.6.RELEASE (*)| | | +--- org.springframework.boot:spring-boot-autoconfigure:2.0.2.RELEASE| | | | \--- org.springframework.boot:spring-boot:2.0.2.RELEASE (*)| | | +--- org.springframework.boot:spring-boot-starter-logging:2.0.2.RELEASE| | | | +--- ch.qos.logback:logback-classic:1.2.3| | | | | +--- ch.qos.logback:logback-core:1.2.3| | | | | \--- org.slf4j:slf4j-api:1.7.25 接下来就好办了，你排除掉ch.qos.logback的依赖就可以了，在你的build.gradle中增加：123configurations &#123; compile.exclude group: &apos;ch.qos.logback&apos;&#125; 这个时候你再重新调试一下看看： 完美，现在是log4j中的实现，得到了我想要的操作。当然了，既然我知道之前项目中的slf4j是logback实现了，那么我自然也可以换成logback的配置，但这就需要我将项目换成用Spring Boot启动，这个改动有点大，如果以后有必要的话，我再将这个exclude删除，换成Spring Boot的形式。 这次Spring Boot帮我们默认启用的是logback，那么有没有什么简单方法可以知道呢？如果你的项目出现了以下的日志输出，说明你的项目当前有不止一个SLF4J的实现组件：12345SLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/project.war/WEB-INF/lib/logback-classic-1.2.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/project.war/WEB-INF/lib/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type [ch.qos.logback.classic.util.ContextSelectorStaticBinder] 因为在org.slf4j.LoggerFactory的bind方法中有关于这方面的输出：123456789101112131415161718192021222324252627282930313233343536373839404142434445private final static void bind() &#123; try &#123; Set&lt;URL&gt; staticLoggerBinderPathSet = null; // skip check under android, see also // http://jira.qos.ch/browse/SLF4J-328 if (!isAndroid()) &#123; // 查找你的当前项目有几个slf4j的实现 staticLoggerBinderPathSet = findPossibleStaticLoggerBinderPathSet(); // 如果多余一个就打印 reportMultipleBindingAmbiguity(staticLoggerBinderPathSet); &#125; // the next line does the binding // 这个是具体选了哪一个实现（重点关注） StaticLoggerBinder.getSingleton(); INITIALIZATION_STATE = SUCCESSFUL_INITIALIZATION; reportActualBinding(staticLoggerBinderPathSet); fixSubstituteLoggers(); replayEvents(); // release all resources in SUBST_FACTORY SUBST_FACTORY.clear(); &#125; catch (NoClassDefFoundError ncde) &#123; String msg = ncde.getMessage(); if (messageContainsOrgSlf4jImplStaticLoggerBinder(msg)) &#123; INITIALIZATION_STATE = NOP_FALLBACK_INITIALIZATION; Util.report("Failed to load class \"org.slf4j.impl.StaticLoggerBinder\"."); Util.report("Defaulting to no-operation (NOP) logger implementation"); Util.report("See " + NO_STATICLOGGERBINDER_URL + " for further details."); &#125; else &#123; failedBinding(ncde); throw ncde; &#125; &#125; catch (java.lang.NoSuchMethodError nsme) &#123; String msg = nsme.getMessage(); if (msg != null &amp;&amp; msg.contains("org.slf4j.impl.StaticLoggerBinder.getSingleton()")) &#123; INITIALIZATION_STATE = FAILED_INITIALIZATION; Util.report("slf4j-api 1.6.x (or later) is incompatible with this binding."); Util.report("Your binding is version 1.5.5 or earlier."); Util.report("Upgrade your binding to version 1.6.x."); &#125; throw nsme; &#125; catch (Exception e) &#123; failedBinding(e); throw new IllegalStateException("Unexpected initialization failure", e); &#125;&#125; 特别要注意的是StaticLoggerBinder.getSingleton();这行代码，StaticLoggerBinder在logback-classic和slf4j-log4j12这两个jar包各有一个，因此，Spring boot是自动选择logback-classic（虽然我在本地运行的时候还是默认进入的slf4j-log4j12，但是会提醒我Source code does not match the bytecode，因此我判断依旧进的是logback-classic），所以只要把logback给exclude掉，就解决了这个问题。 现在看问题，更加关注源代码，因为这可以让我们更加快速定位问题，并且也能据此大致猜出其解决方案。希望大家能一起看看源代码，如果你有什么发现，可以在下方留言，我将和你一起讨论。]]></content>
      <tags>
        <tag>log4j</tag>
        <tag>Spring Boot</tag>
        <tag>logback</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty 心跳相关(1)]]></title>
    <url>%2F2018%2F10%2F23%2FNetty-%E5%BF%83%E8%B7%B3%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[无论是B/S还是C/S架构，如果你用的是长连接，那么心跳是必不可少的。Netty提供了对心跳机制的天然支持，今天结合例子特地学习了一下。 首先，我们来设想一下何时需要发送心跳。假设你做的是一款棋牌类小游戏，那么当玩家登陆游戏后肯定是先进入大厅，再选择一张合适的桌子正式开始游戏。此时玩家的客户端与服务器建立的这一次session（会话）应该是长久保持着，如果服务器端保存着大量的session，那么整个服务器就会越来越卡，最终整个服务都会挂掉。 为了预防这种情况，我们需要清理掉一些已经不用的或者理论上不会再用的session，比如：在手机上，如果我们在游戏中，突然接到一个电话或者退回桌面，这个时候我们的游戏客户端理论上就不会再主动向我们发送任何消息。这时候，心跳就派上用场了。 心跳，是为了证明自己还活着。因此，这里的心跳，说白了就是客户端向服务器端发送一次请求，服务器端相应，这样客户端就知道了服务器端是alive(活着的)；服务器端向客户端发送一次心跳，客户端相应，这样服务器端就知道了客户端是alive。 知道了心跳的大致概念，那现在我们就需要知道Netty中是如何实现心跳，这就引出了两个类：IdleStateHandler、ChannelInboundHandlerAdapter IdleStateHandler大致作用 当连接的空闲时间（无论是读或者是写）太长时，都会触发IdleStateEvent事件。你可以写一个类继承ChannelInboundHandlerAdapter，重写userEventTriggered方法，来处理这类空闲事件。 知道了其大致作用，那么接下来就看看我们到底该如何使用了。 IdleStateHandler有3个构造方法，主要针对这4个属性，分别是：1234private final boolean observeOutput;// 是否考虑出站时较慢的情况。默认值是false（一般不考虑）。private final long readerIdleTimeNanos; // 读事件空闲时间，0 代表禁用事件private final long writerIdleTimeNanos;// 写事件空闲时间，0 代表禁用事件private final long allIdleTimeNanos; //读或写空闲时间，0 代表禁用事件 上面的三个时间，默认是秒，你也可以在构造的时候指定。 当你在pipeline中加入了该handler之后： pipeline.addLast(new IdleStateHandler(30, 90, 0)); // 这个代表只考虑读空闲30秒或写空闲90秒的情况 则会先调用handlerAdded方法：1234567891011@Overridepublic void handlerAdded(ChannelHandlerContext ctx) throws Exception &#123; if (ctx.channel().isActive() &amp;&amp; ctx.channel().isRegistered()) &#123; // channelActive() event has been fired already, which means this.channelActive() will // not be invoked. We have to initialize here instead. initialize(ctx); &#125; else &#123; // channelActive() event has not been fired yet. this.channelActive() will be invoked // and initialization will occur there. &#125;&#125; 如果channel正常，则调用initialize方法：1234567891011121314151617181920212223242526272829private byte state; // 0 - none, 1 - initialized, 2 - destroyedprivate void initialize(ChannelHandlerContext ctx) &#123; // Avoid the case where destroy() is called before scheduling timeouts. // See: https://github.com/netty/netty/issues/143 switch (state) &#123; case 1: // 避免重复添加 case 2: // 如果处于destoryed状态，则不需要添加 return; &#125; state = 1; initOutputChanged(ctx); lastReadTime = lastWriteTime = ticksInNanos(); // 当前时间 // 添加相应的定时调度任务 if (readerIdleTimeNanos &gt; 0) &#123; // readerIdleTimeNanos时间后，执行ReaderIdleTimeoutTask里面的方法 readerIdleTimeout = schedule(ctx, new ReaderIdleTimeoutTask(ctx), readerIdleTimeNanos, TimeUnit.NANOSECONDS); &#125; if (writerIdleTimeNanos &gt; 0) &#123; writerIdleTimeout = schedule(ctx, new WriterIdleTimeoutTask(ctx), writerIdleTimeNanos, TimeUnit.NANOSECONDS); &#125; if (allIdleTimeNanos &gt; 0) &#123; allIdleTimeout = schedule(ctx, new AllIdleTimeoutTask(ctx), allIdleTimeNanos, TimeUnit.NANOSECONDS); &#125;&#125; ReaderIdleTimeoutTask、WriterIdleTimeoutTask、AllIdleTimeoutTask均继承自类AbstractIdleTask12345678910111213141516171819private abstract static class AbstractIdleTask implements Runnable &#123; private final ChannelHandlerContext ctx; AbstractIdleTask(ChannelHandlerContext ctx) &#123; this.ctx = ctx; &#125; @Override public void run() &#123; if (!ctx.channel().isOpen()) &#123; return; &#125; run(ctx); &#125; // 子类需要实现的方法 protected abstract void run(ChannelHandlerContext ctx);&#125; 以ReaderIdleTimeoutTask为例：12345678910111213141516171819202122232425262728293031323334private final class ReaderIdleTimeoutTask extends AbstractIdleTask &#123; ReaderIdleTimeoutTask(ChannelHandlerContext ctx) &#123; super(ctx); &#125; @Override protected void run(ChannelHandlerContext ctx) &#123; long nextDelay = readerIdleTimeNanos; if (!reading) &#123; // 如果不在读(channelRead时会被置为true，cahnnelReadComplete时会被置为false) nextDelay -= ticksInNanos() - lastReadTime; &#125; if (nextDelay &lt;= 0) &#123; // 说明读空闲时间达到或超过预设时间 // Reader is idle - set a new timeout and notify the callback. readerIdleTimeout = schedule(ctx, this, readerIdleTimeNanos, TimeUnit.NANOSECONDS); // firstReaderIdleEvent，是否是第一次读空闲事件(该标志位会在下一次channelRead触发时改成true，所以应该理解在一次读取完成后，这个读空闲事件是不是第一次) boolean first = firstReaderIdleEvent; firstReaderIdleEvent = false; try &#123; // 生成一个IdleStateEvent对象 IdleStateEvent event = newIdleStateEvent(IdleState.READER_IDLE, first); // 找到下一个ChannelInboundHandler类（或其子类）的handler，触发其userEventTrigger(可以参考AbstractChannelHandlerContext的fireUserEventTriggered方法) channelIdle(ctx, event); &#125; catch (Throwable t) &#123; ctx.fireExceptionCaught(t); &#125; &#125; else &#123; // 要么正在读，要么读空闲时间小于预设时间 // Read occurred before the timeout - set a new timeout with shorter delay. readerIdleTimeout = schedule(ctx, this, nextDelay, TimeUnit.NANOSECONDS); &#125; &#125;&#125; schedule方法可以理解为将定时调度事件放进一个队列当中（我是在AbstractScheduledEventExecutor里找到的scheduledTaskQueue().add(task);，但这里面的代码我还没看明白，有兴趣的你可以自己研究，研究完后如果有空可在下方评论）。channelIdle(ctx, event)方法时找到下一个ChannelInboundHandler类（或其子类）的handler，因此你写的继承自ChannelInboundHandler的handler，一定要添加在IdleStateHandler的后面，比如：12pipeline.addLast(new IdleStateHandler(30, 90, 0));pipeline.addLast(heartbeatHandler); ChannelInboundHandler它就很简单了，因为上面说了，channelIdle会调用ChannelInboundHandler的userEventTrigger，所以你只要自己写一个类继承ChannelInboundHandler，并重写它的userEventTrigger方法。比如：1234567891011121314151617181920212223242526272829303132// 用Sharable是因为我的每一个pipeline中用的都是同样的handler@Sharablepublic class NettyHeartbeatHandler extends ChannelInboundHandlerAdapter &#123; private final IHeartbeatFactory factory; public NettyHeartbeatHandler(IHeartbeatFactory factory) &#123; Preconditions.checkNotNull(factory); this.factory = factory; &#125; @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; if (!(evt instanceof IdleStateEvent)) &#123; super.userEventTriggered(ctx, evt); return; &#125; IdleStateEvent event = (IdleStateEvent) evt; if (event.state() == IdleState.READER_IDLE) &#123; // 如果是读空闲，则关闭当前会话 ctx.close(); // 此时会触发下一个ChannelOutboundHandler的close方法，你可以在自己写的handler中进行断线操作 &#125; else if (event.state() == IdleState.WRITER_IDLE) &#123; // 如果是写空闲，则向客户端发送心跳请求包，如果客户端不返回心跳相应包，则说明客户端断线，下一次就将触发读空闲事件。这也是为了向客户端证明服务器端alive ctx.writeAndFlush( new BinaryWebSocketFrame( Unpooled.copiedBuffer(factory.getHeartbeatRequest().toByteArray()) ) ); &#125; &#125;&#125; 因此，以上就是关于用Netty实现心跳的简单介绍。其中带大家重点看了服务器端应该在什么情况下发起一次心跳请求，应该是长久没有收到消息时（可能是有业务含义的消息或者是一个心跳包）。如果大家有什么想法可以在下方评论。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitalk Error: Validation Failed]]></title>
    <url>%2F2018%2F09%2F30%2Fgitalk%20Error%20Validation%20Failed%2F</url>
    <content type="text"><![CDATA[我现在博客的评论系统用的是gitalk，网上教程有很多，我参考的是这份教程。 当我按照网上的说法搭好后，确实是可以利用issue进行评论了，但我在新发表文章时，竟然报错了： 当时我心里一凉，难道和gitment一样，gitalk也凉了？后来上网查了一下，发现是github现在要求issue的label name不能超过50。（奥，现在我才知道，原来gitalk应该是利用label进行筛选，取得当前评论所属的issus。但后来看了一下gitalk的源代码和github关于issue的api，issue的查找应该和你的number有关，而gitalk是当你没有number时就用id代替，看的有点晕。PS：本人在前端方面纯属小白） 好了，那就想想有什么办法可以保证名字的长度可以不超过50吧。没错，就是md5,加密过后都是32位长度，且唯一。当然了，这个也是在gitalk的issue里查到的，接下来就来看看具体应该怎么做吧。 找到js版的md5算法首推的自然是别人已经造好的成熟的轮子，JavaScript-MD5这个应该是可以的，亲测有效。 你只要在你的主题(比如我的就是next)下的source\js\src目录中创放入md5.js.min文件即可。 修改gitalk.swig文件原本你的文件内容应该是：12345678910111213141516&#123;% if page.comments &amp;&amp; theme.gitalk.enable %&#125; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://unpkg.com/gitalk/dist/gitalk.css&quot;&gt; &lt;script src=&quot;https://unpkg.com/gitalk/dist/gitalk.min.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; var gitalk = new Gitalk(&#123; clientID: &apos;&#123;&#123; theme.gitalk.ClientID &#125;&#125;&apos;, clientSecret: &apos;&#123;&#123; theme.gitalk.ClientSecret &#125;&#125;&apos;, repo: &apos;&#123;&#123; theme.gitalk.repo &#125;&#125;&apos;, owner: &apos;&#123;&#123; theme.gitalk.githubID &#125;&#125;&apos;, admin: [&apos;&#123;&#123; theme.gitalk.adminUser &#125;&#125;&apos;], id: location.pathname, distractionFreeMode: &apos;&#123;&#123; theme.gitalk.distractionFreeMode &#125;&#125;&apos; &#125;) gitalk.render(&apos;gitalk-container&apos;) &lt;/script&gt;&#123;% endif %&#125; 现在改成即可(修改了第4行和第12行)1234567891011121314151617&#123;% if page.comments &amp;&amp; theme.gitalk.enable %&#125; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://unpkg.com/gitalk/dist/gitalk.css&quot;&gt; &lt;script src=&quot;https://unpkg.com/gitalk/dist/gitalk.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;/js/src/md5.min.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; var gitalk = new Gitalk(&#123; clientID: &apos;&#123;&#123; theme.gitalk.ClientID &#125;&#125;&apos;, clientSecret: &apos;&#123;&#123; theme.gitalk.ClientSecret &#125;&#125;&apos;, repo: &apos;&#123;&#123; theme.gitalk.repo &#125;&#125;&apos;, owner: &apos;&#123;&#123; theme.gitalk.githubID &#125;&#125;&apos;, admin: [&apos;&#123;&#123; theme.gitalk.adminUser &#125;&#125;&apos;], id: md5(location.pathname), distractionFreeMode: &apos;&#123;&#123; theme.gitalk.distractionFreeMode &#125;&#125;&apos; &#125;) gitalk.render(&apos;gitalk-container&apos;) &lt;/script&gt;&#123;% endif %&#125; 然后重新发布就ok了，gitalk又可以正确创建issue了，你又可以继续评论了。 需要注意的问题因为gitalk关联issue是通过number，你没有number的时候，它会直接利用你的id，而id的这个生成条件又被你修改了，因此你之前评论是无法和你的文章关联上了。如果对js稍微感兴趣的话，应该可以顺着这个思路往下能解决。博主有空也会试试，就当研究研究js，大家要是有成功的案例，可以在通过评论告知，毕竟这也是造福大家。附上gitalk源码地址。]]></content>
      <categories>
        <category>解决问题</category>
      </categories>
      <tags>
        <tag>gitalk</tag>
        <tag>Error</tag>
        <tag>Validation Failed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos6安装shadowsocks及配置]]></title>
    <url>%2F2018%2F09%2F30%2FCentos6%E5%AE%89%E8%A3%85shadowsocks%E5%8F%8A%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[买下搬瓦工的服务器，很多人首先会希望配置多个端口方便使用，这时候就需要安装shadowsocks来解决。现在我来介绍一下Centos6系统下shadowsocks的安装及配置过程。 这篇文章原是我在CSDN上发表的一篇博客，但在去年年底时莫名其妙被删除了，因此在这里，我把文章搬运过来，也是方便自己查看里面的一些命令。 这是一个搬瓦工的购买教程网站 安装python、pip、shadowsocks安装python： yum install python-setuptools 安装wget yum install wget 安装pip：（先下载再安装）1234wget https://pypi.python.org/packages/source/p/pip/pip-1.3.1.tar.gz --no-check-certificatetar -xzvf pip-1.3.1.tar.gzcd pip-1.3.1python setup.py install 安装shadowsocks pip install shadowsocks 配置shadowsocks首先创建配置文件/etc/shadowsocks.json touch /etc/shadowsocks.json 创建并编辑shadowsocks.json vi /etc/shadowsocks.json 现在要决定你是否需要开多端口，因为开出多个端口，每个端口的速度影响不大，但如果用同一个端口，速度会有所影响。 shadowsocks.json内容为：123456789101112&#123; &quot;server&quot;:&quot;你的IP地址&quot;, &quot;local_address&quot;: &quot;127.0.0.1&quot;, &quot;local_port&quot;:1080, &quot;port_password&quot;:&#123; &quot;端口号1&quot;:&quot;密码1&quot;, &quot;端口号2&quot;:&quot;密码2&quot; &#125;, &quot;timeout&quot;:600, &quot;method&quot;:&quot;rc4-md5&quot;, &quot;fast_open&quot;: false&#125; 对应你本地的shadowsocks配置为： 这时可以在Centos上运行shadowsocks服务： ssserver -c /etc/shadowsocks.json -d start 此时理论上你就可以科学上网了。 停止shadowsocks服务命令： ssserver -c /etc/shadowsocks.json -d stop 可能遇到的问题当你设置好配置文件并且启动之后，发现本地并不能上外网，其实可以通过shadowsocks的更新PAC功能查看是否可以连接外网： 如果更新失败，则代表无法连接外网，这时候请看一下你的服务器上设置的端口是否开启： netstat -ntlp 我开启了443、7788、7789、7790四个端口，如果你发现此处没有你的端口号，代表端口未打开 此时你需要先关闭shadowsocks，使用关闭命令，然后打开你所需要的端口。 利用iptables打开端口命令: /sbin/iptables -I INPUT -p tcp --dport 端口号 -j ACCEPT 保存你刚刚添加的规则: /etc/rc.d/init.d/iptables save 查看打开的端口： /etc/init.d/iptables status 现在这里会显示出你刚刚打开的端口。 现在开启你服务器上的shadowsocks，再用查看端口命令，应该就显示出你的端口已经打开了。 资源下载shadowsocks相关下载包安卓版本官方下载电脑版Windows 7及之前的版本电脑版Windows 8及之后的版本iOS教程]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初章]]></title>
    <url>%2F2018%2F09%2F29%2F%E5%88%9D%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[第一次使用hexo写博客，希望能有一个不错的开始。]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
</search>
